# ğŸ™ï¸ Realtime Transcript

á»¨ng dá»¥ng web chuyá»ƒn Ä‘á»•i giá»ng nÃ³i thÃ nh vÄƒn báº£n (Speech-to-Text) theo thá»i gian thá»±c vÃ  tá»« file audio/video.

- Há»— trá»£ 2 backend model:
  - Whisper (qua `faster-whisper`) â€” máº·c Ä‘á»‹nh, tá»‘i Æ°u realtime
  - SenseVoice (qua `funasr`) â€” thay tháº¿, cÃ³ fallback timestamp cho file upload

## âœ¨ TÃ­nh nÄƒng

- **Realtime Transcription**: Chuyá»ƒn Ä‘á»•i giá»ng nÃ³i thÃ nh vÄƒn báº£n theo thá»i gian thá»±c qua WebSocket (stream Full Transcript + Segments cÃ³ timestamp)
- **File Upload**: Upload vÃ  transcribe file audio/video (mp3, wav, m4a, mp4, avi, mov, ...), tráº£ vá» full transcript vÃ  danh sÃ¡ch segments cÃ³ timestamp
- **Speaker Detection (Nháº­n diá»‡n ngÆ°á»i nÃ³i)**: TÃ¹y chá»n nháº­n diá»‡n vÃ  phÃ¢n biá»‡t nhiá»u ngÆ°á»i nÃ³i trong audio, há»— trá»£ cáº¥u hÃ¬nh sá»‘ lÆ°á»£ng ngÆ°á»i nÃ³i tá»‘i Ä‘a (máº·c Ä‘á»‹nh: 2)
- **Äa ngÃ´n ngá»¯**: Há»— trá»£ nhiá»u ngÃ´n ngá»¯ vá»›i tá»± Ä‘á»™ng phÃ¡t hiá»‡n ngÃ´n ngá»¯
- **Timestamps**: Realtime cÃ³ timestamp theo buffer; Upload cÃ³ timestamp tá»« model hoáº·c Ä‘Æ°á»£c suy Ä‘oÃ¡n (fallback) theo Ä‘á»™ dÃ i ná»™i dung
- **RTF (Real-Time Factor)**: TÃ­nh toÃ¡n vÃ  hiá»ƒn thá»‹ RTF cho file upload Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t xá»­ lÃ½
- **Auto-detect WebSocket URL**: Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  cáº¥u hÃ¬nh WebSocket URL tá»« port cá»§a backend
- **Error Handling**: Há»‡ thá»‘ng thÃ´ng bÃ¡o lá»—i/thÃ nh cÃ´ng vá»›i tá»± Ä‘á»™ng dá»«ng khi cÃ³ lá»—i
- **UI Protection**: Tá»± Ä‘á»™ng disable cÃ¡c tÃ¹y chá»n cáº¥u hÃ¬nh khi Ä‘ang xá»­ lÃ½ Ä‘á»ƒ trÃ¡nh thay Ä‘á»•i khÃ´ng mong muá»‘n
- **Drag & Drop**: KÃ©o tháº£ file Ä‘á»ƒ upload dá»… dÃ ng
- **Progress Tracking**: Theo dÃµi tiáº¿n trÃ¬nh upload vÃ  xá»­ lÃ½

## ğŸ—ï¸ Kiáº¿n trÃºc

- **Backend**: FastAPI (WebSocket cho realtime, REST cho upload)
- **Frontend**: HTML/JavaScript vá»›i WebSocket client
- **Model**: Whisper (`faster-whisper`) hoáº·c SenseVoice (`funasr`)

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Pháº§n má»m
- Python 3.8+
- ffmpeg (Ä‘á»ƒ xá»­ lÃ½ video files)

### Pháº§n cá»©ng
- **CPU**: MÃ¡y tÃ­nh cÃ³ CPU Ä‘á»§ máº¡nh (khuyáº¿n nghá»‹: 4+ cores)
- **GPU**: TÃ¹y chá»n, nhÆ°ng khuyáº¿n nghá»‹ náº¿u muá»‘n xá»­ lÃ½ nhanh hÆ¡n (CUDA compatible)

### CÃ i Ä‘áº·t ffmpeg

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

**macOS:**
```bash
brew install ffmpeg
```

**Windows:**
Táº£i tá»« [ffmpeg.org](https://ffmpeg.org/download.html) vÃ  thÃªm vÃ o PATH

**Conda:**
```bash
conda install -c conda-forge ffmpeg
```

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone https://github.com/trunghoang2002/realtime-transcript.git
cd realtime-transcript
```

### 2. Táº¡o mÃ´i trÆ°á»ng áº£o (khuyáº¿n nghá»‹)
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate  # Windows
```

### 3. CÃ i Ä‘áº·t dependencies
```bash
cd backend
pip install -r requirements.txt
```

**GPU (CUDA)**
- Khuyáº¿n nghá»‹ CUDA 12.1 + cuDNN 9
- Dá»± Ã¡n cÃ³ sáºµn script Ä‘á»ƒ set mÃ´i trÆ°á»ng CUDA/cuDNN vÃ  cháº¡y server:
  - Whisper: `backend/run_main_with_cuda.sh`
  - SenseVoice: `backend/run_main_sensevoice_with_cuda.sh`

### 4. Cáº¥u hÃ¬nh model (tÃ¹y chá»n)

Chá»‰nh sá»­a `backend/main.py` (Whisper) hoáº·c `backend/main_sensevoice.py` (SenseVoice) Ä‘á»ƒ thay Ä‘á»•i model vÃ  device:

```python
MODEL_NAME = "small"   # "small" (nhanh), "medium" (chÃ­nh xÃ¡c), "large-v3" (náº·ng)
DEVICE = "cpu"         # "cuda" náº¿u cÃ³ GPU, "cpu" náº¿u khÃ´ng
COMPUTE_TYPE = "int8"  # "float16" trÃªn GPU, "int8" hoáº·c "int8_float16" trÃªn CPU
```

**Khuyáº¿n nghá»‹:**
- Whisper + CPU: `MODEL_NAME = "small"`, `DEVICE = "cpu"`, `COMPUTE_TYPE = "int8"`
- Whisper + GPU: `MODEL_NAME = "medium"`, `DEVICE = "cuda"`, `COMPUTE_TYPE = "float16"`
- SenseVoice + GPU: `DEVICE = "cuda"`
- SenseVoice + CPU: `DEVICE = "cpu"`

## â–¶ï¸ Cháº¡y á»©ng dá»¥ng

### Khá»Ÿi Ä‘á»™ng server
```bash
cd backend
python main.py
```

Server sáº½ cháº¡y táº¡i: `http://localhost:8917`

### Cháº¡y vá»›i CUDA (náº¿u cÃ³ GPU)

**YÃªu cáº§u:**
- CUDA 12.1 Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t
- File `~/activate_cuda121.sh` Ä‘á»ƒ activate CUDA 12.1
- Conda environment `v2t` Ä‘Ã£ Ä‘Æ°á»£c táº¡o vÃ  cÃ³ cÃ¡c dependencies

**Cháº¡y server:**
```bash
cd backend
./run_main_with_cuda.sh          # Whisper (port 8917)
# hoáº·c
./run_main_sensevoice_with_cuda.sh  # SenseVoice (port 8918)
```

**Vá»›i auto-reload (development):**
```bash
./run_main_with_cuda.sh --reload          # Whisper
./run_main_sensevoice_with_cuda.sh --reload  # SenseVoice
```

**LÆ°u Ã½:**
- Scripts tá»± Ä‘á»™ng:
  - Activate conda environment `v2t`
  - Setup CUDA paths vÃ  cuDNN libraries tá»« conda env
  - Cáº¥u hÃ¬nh `LD_LIBRARY_PATH` cho cuDNN vÃ  PyTorch libraries
  - Sá»­ dá»¥ng GPU device 1 (`CUDA_VISIBLE_DEVICES=1`)
- Whisper cháº¡y trÃªn port **8917**, SenseVoice cháº¡y trÃªn port **8918**
- Náº¿u gáº·p lá»—i, kiá»ƒm tra:
  - Conda env `v2t` Ä‘Ã£ Ä‘Æ°á»£c táº¡o chÆ°a
  - File `~/activate_cuda121.sh` cÃ³ tá»“n táº¡i khÃ´ng
  - CUDA 12.1 Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t Ä‘Ãºng chÆ°a

### Truy cáº­p á»©ng dá»¥ng
Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p: `http://localhost:8917`

## ğŸ“¡ API Endpoints

### WebSocket: `/ws`

Káº¿t ná»‘i WebSocket Ä‘á»ƒ realtime transcription.

**Protocol:**
1. Client gá»­i message báº¯t Ä‘áº§u:
```json
{
  "event": "start",
  "sample_rate": 16000,
  "format": "pcm16",
  "language": "vi",  // hoáº·c "auto", "en", "ja", ...
  "detect_speaker": false,  // (optional) Báº­t/táº¯t nháº­n diá»‡n ngÆ°á»i nÃ³i
  "max_speakers": 2  // (optional) Sá»‘ lÆ°á»£ng ngÆ°á»i nÃ³i tá»‘i Ä‘a (chá»‰ khi detect_speaker=true)
}
```

2. Client gá»­i audio chunks dÆ°á»›i dáº¡ng binary (PCM16 mono 16kHz)

3. Server tráº£ vá»:
```json
{"type": "ready"}
{"type": "partial", "text": "...", "speaker_id": "spk_01", "language": "vi", "language_probability": 0.95, "segments": [{"start": 0.0, "end": 1.0, "text": "...", "speaker_id": "spk_01"}]}
{"type": "final", "text": ""}
{"type": "error", "message": "..."}  // Náº¿u cÃ³ lá»—i
```

4. Client gá»­i Ä‘á»ƒ dá»«ng:
```json
{"event": "stop"}
```

### REST API: `POST /api/transcribe`

Upload file audio/video Ä‘á»ƒ transcribe.

**Request:**
- Method: `POST`
- Content-Type: `multipart/form-data`
- Form fields:
  - `file`: File audio/video (required)
  - `language`: (optional) NgÃ´n ngá»¯ ("vi", "en", "auto", ...)
  - `detect_speaker`: (optional) "true" hoáº·c "false" - Báº­t/táº¯t nháº­n diá»‡n ngÆ°á»i nÃ³i (máº·c Ä‘á»‹nh: "false")
  - `max_speakers`: (optional) Sá»‘ lÆ°á»£ng ngÆ°á»i nÃ³i tá»‘i Ä‘a (chá»‰ khi detect_speaker="true", máº·c Ä‘á»‹nh: 2)

**Response:**
```json
{
  "success": true,
  "filename": "audio.mp3",
  "text": "Full transcript text...",
  "segments": [
    {
      "start": 0.0,
      "end": 5.2,
      "text": "Äoáº¡n text Ä‘áº§u tiÃªn",
      "speaker_id": "spk_01"  // Chá»‰ cÃ³ khi detect_speaker=true
    },
    ...
  ],
  "language": "vi",
  "language_probability": 0.95,
  "rtf": 0.234  // Real-Time Factor: processing_time / audio_duration
}
```

**Example vá»›i curl:**
```bash
# Upload cÆ¡ báº£n
curl -X POST http://localhost:8917/api/transcribe \
  -F "file=@audio.mp3" \
  -F "language=vi"

# Upload vá»›i speaker detection
curl -X POST http://localhost:8917/api/transcribe \
  -F "file=@audio.mp3" \
  -F "language=vi" \
  -F "detect_speaker=true" \
  -F "max_speakers=3"
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
realtime-transcript/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                          # FastAPI server vá»›i Whisper model
â”‚   â”œâ”€â”€ main_sensevoice.py               # FastAPI server vá»›i SenseVoice model
â”‚   â”œâ”€â”€ requirements.txt                 # Python dependencies
â”‚   â”œâ”€â”€ constraints.txt                  # Version constraints cho dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ run_main_with_cuda.sh            # Script cháº¡y Whisper vá»›i CUDA support
â”‚   â”œâ”€â”€ run_main_sensevoice_with_cuda.sh # Script cháº¡y SenseVoice vá»›i CUDA support
â”‚   â”œâ”€â”€ activate_cuda_env.sh             # Script activate CUDA environment
â”‚   â”‚
â”‚   â”œâ”€â”€ get_audio.py                     # Utilities Ä‘á»ƒ decode audio/video files
â”‚   â”œâ”€â”€ silero_vad.py                    # VAD (Voice Activity Detection) sá»­ dá»¥ng Silero VAD
â”‚   â”œâ”€â”€ fix_speechbrain.py               # Patch compatibility cho SpeechBrain vá»›i huggingface_hub
â”‚   â”‚
â”‚   â”œâ”€â”€ check_cuda.py                    # Script kiá»ƒm tra CUDA availability
â”‚   â”‚
â”‚   â”œâ”€â”€ whisper_docs.md                  # TÃ i liá»‡u vá» Whisper model
â”‚   â”œâ”€â”€ sensevoice_docs.md               # TÃ i liá»‡u vá» SenseVoice model
â”‚   â”œâ”€â”€ whisper_vs_sensevoice.md         # So sÃ¡nh Whisper vs SenseVoice
â”‚   â”‚
â”‚   â”œâ”€â”€ eval/                            # ThÆ° má»¥c evaluation/testing
â”‚   â”‚   â”œâ”€â”€ eval.py                      # Script Ä‘Ã¡nh giÃ¡ model
â”‚   â”‚   â”œâ”€â”€ en/                          # Test cases tiáº¿ng Anh
â”‚   â”‚   â””â”€â”€ ja/                          # Test cases tiáº¿ng Nháº­t
â”‚   â”‚
â”‚   â”œâ”€â”€ note.txt                         # Ghi chÃº phÃ¡t triá»ƒn
â”‚   â””â”€â”€ __pycache__/                     # Python cache (tá»± Ä‘á»™ng táº¡o)
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                       # Frontend UI (HTML + JavaScript)
â”‚
â””â”€â”€ README.md                            # TÃ i liá»‡u nÃ y
```

### MÃ´ táº£ cÃ¡c thÃ nh pháº§n chÃ­nh

#### Backend Core Files
- **`main.py`**: Server chÃ­nh sá»­ dá»¥ng Whisper model (`faster-whisper`) cho realtime vÃ  file transcription
- **`main_sensevoice.py`**: Server thay tháº¿ sá»­ dá»¥ng SenseVoice model (`funasr`) vá»›i kháº£ nÄƒng fallback timestamp tá»‘t hÆ¡n

#### Utility Modules
- **`get_audio.py`**: Xá»­ lÃ½ decode audio/video files thÃ nh numpy array (16kHz mono) sá»­ dá»¥ng `av` (PyAV)
- **`silero_vad.py`**: Voice Activity Detection Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c Ä‘oáº¡n cÃ³ giá»ng nÃ³i, loáº¡i bá» im láº·ng
- **`fix_speechbrain.py`**: Patch Ä‘á»ƒ fix compatibility issue giá»¯a SpeechBrain vÃ  huggingface_hub (cáº§n cho speaker detection)

#### CUDA Scripts
- **`run_main_with_cuda.sh`**: Script tá»± Ä‘á»™ng setup CUDA/cuDNN vÃ  cháº¡y Whisper server trÃªn port 8917
- **`run_main_sensevoice_with_cuda.sh`**: Script tá»± Ä‘á»™ng setup CUDA/cuDNN vÃ  cháº¡y SenseVoice server trÃªn port 8918
- **`activate_cuda_env.sh`**: Script helper Ä‘á»ƒ activate CUDA environment
- **`check_cuda.py`**: Script kiá»ƒm tra CUDA cÃ³ sáºµn vÃ  hoáº¡t Ä‘á»™ng khÃ´ng

#### Documentation
- **`whisper_docs.md`**: TÃ i liá»‡u chi tiáº¿t vá» cÃ¡ch sá»­ dá»¥ng Whisper model
- **`sensevoice_docs.md`**: TÃ i liá»‡u chi tiáº¿t vá» cÃ¡ch sá»­ dá»¥ng SenseVoice model
- **`whisper_vs_sensevoice.md`**: So sÃ¡nh Æ°u/nhÆ°á»£c Ä‘iá»ƒm giá»¯a 2 models

#### Evaluation
- **`eval/`**: ThÆ° má»¥c chá»©a scripts vÃ  test cases Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng transcription
  - `eval.py`: Script cháº¡y evaluation
  - `en/`, `ja/`: Test cases cho cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau

## ğŸ¯ CÃ¡ch sá»­ dá»¥ng

### Realtime Transcription

1. Má»Ÿ tab **"Realtime"**
2. Cáº¥u hÃ¬nh:
   - **WebSocket URL**: Tá»± Ä‘á»™ng detect tá»« backend (cÃ³ thá»ƒ chá»‰nh sá»­a náº¿u cáº§n)
   - **NgÃ´n ngá»¯**: Chá»n ngÃ´n ngá»¯ (hoáº·c "Tá»± Ä‘á»™ng")
   - **Detect speaker**: Báº­t/táº¯t nháº­n diá»‡n ngÆ°á»i nÃ³i (tÃ¹y chá»n)
   - **Max speaker**: Sá»‘ lÆ°á»£ng ngÆ°á»i nÃ³i tá»‘i Ä‘a (chá»‰ hiá»‡n khi báº­t Detect speaker, máº·c Ä‘á»‹nh: 2)
3. Nháº¥n **"Start"** vÃ  cho phÃ©p truy cáº­p microphone
   - CÃ¡c tÃ¹y chá»n cáº¥u hÃ¬nh sáº½ tá»± Ä‘á»™ng bá»‹ disable khi Ä‘ang xá»­ lÃ½
4. Báº¯t Ä‘áº§u nÃ³i, transcript sáº½ hiá»ƒn thá»‹ theo thá»i gian thá»±c theo 2 pháº§n:
   - **Full Transcript**: Ná»‘i liÃªn tá»¥c ná»™i dung (cÃ³ speaker ID náº¿u báº­t detect speaker)
   - **Segments**: Danh sÃ¡ch cÃ¡c Ä‘oáº¡n cÃ³ timestamp (start â†’ end) vÃ  speaker ID (náº¿u cÃ³)
5. Nháº¥n **"Stop"** Ä‘á»ƒ dá»«ng
   - CÃ¡c tÃ¹y chá»n cáº¥u hÃ¬nh sáº½ Ä‘Æ°á»£c enable láº¡i

**LÆ°u Ã½**: Náº¿u cÃ³ lá»—i xáº£y ra, há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng dá»«ng vÃ  hiá»ƒn thá»‹ thÃ´ng bÃ¡o lá»—i.

### Upload File

1. Má»Ÿ tab **"Upload File"**
2. Cáº¥u hÃ¬nh:
   - **NgÃ´n ngá»¯**: Chá»n ngÃ´n ngá»¯ (hoáº·c "Tá»± Ä‘á»™ng")
   - **Detect speaker**: Báº­t/táº¯t nháº­n diá»‡n ngÆ°á»i nÃ³i (tÃ¹y chá»n)
   - **Max speaker**: Sá»‘ lÆ°á»£ng ngÆ°á»i nÃ³i tá»‘i Ä‘a (chá»‰ hiá»‡n khi báº­t Detect speaker, máº·c Ä‘á»‹nh: 2)
3. KÃ©o tháº£ file vÃ o vÃ¹ng upload hoáº·c click **"Chá»n File"**
   - CÃ¡c tÃ¹y chá»n cáº¥u hÃ¬nh sáº½ tá»± Ä‘á»™ng bá»‹ disable khi Ä‘ang xá»­ lÃ½
4. Chá» xá»­ lÃ½:
   - Progress bar sáº½ hiá»ƒn thá»‹ tiáº¿n trÃ¬nh upload
   - ThÃ´ng bÃ¡o thÃ nh cÃ´ng/lá»—i sáº½ xuáº¥t hiá»‡n á»Ÿ gÃ³c trÃªn bÃªn pháº£i
5. Xem káº¿t quáº£:
   - **Full Transcript**: ToÃ n bá»™ ná»™i dung (cÃ³ speaker ID náº¿u báº­t detect speaker)
   - **Segments**: Danh sÃ¡ch cÃ¡c Ä‘oáº¡n cÃ³ timestamp vÃ  speaker ID (náº¿u cÃ³)
   - **RTF**: Real-Time Factor (hiá»‡u suáº¥t xá»­ lÃ½) - RTF < 1.0 nghÄ©a lÃ  xá»­ lÃ½ nhanh hÆ¡n thá»i gian thá»±c

## âš™ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### Thay Ä‘á»•i port

Sá»­a trong `backend/main.py`:
```python
uvicorn.run("main:app", host="0.0.0.0", port=8917, reload=True)
```

### Thay Ä‘á»•i WebSocket URL

WebSocket URL tá»± Ä‘á»™ng detect tá»« port cá»§a backend. Náº¿u cáº§n chá»‰nh sá»­a thá»§ cÃ´ng, sá»­a trong `frontend/index.html`:
```html
<input id="wsUrl" type="text" value="ws://localhost:8917/ws">
```

Hoáº·c chá»‰nh sá»­a function `getWebSocketUrl()` trong JavaScript Ä‘á»ƒ thay Ä‘á»•i logic auto-detect.

### Tá»‘i Æ°u hÃ³a cho realtime

Trong `run_transcribe_on_buffer()`:
- `beam_size=1`: Tá»‘i Æ°u tá»‘c Ä‘á»™
- `best_of=1`: Tá»‘i Æ°u tá»‘c Ä‘á»™
- `condition_on_previous_text=False`: Giáº£m Ä‘á»™ trá»…

### Tá»‘i Æ°u hÃ³a cho file upload

Trong `transcribe_file()`:
- `beam_size=5`: TÄƒng Ä‘á»™ chÃ­nh xÃ¡c
- `best_of=5`: TÄƒng Ä‘á»™ chÃ­nh xÃ¡c
- `condition_on_previous_text=True`: Sá»­ dá»¥ng ngá»¯ cáº£nh

## ğŸ› Troubleshooting

### Lá»—i: "max() arg is an empty sequence"
- **NguyÃªn nhÃ¢n**: Audio quÃ¡ ngáº¯n hoáº·c hoÃ n toÃ n im láº·ng
- **Giáº£i phÃ¡p**: ÄÃ£ Ä‘Æ°á»£c xá»­ lÃ½ tá»± Ä‘á»™ng, chá»‰ cáº§n thá»­ láº¡i

### Lá»—i: "ffmpeg not found"
- **NguyÃªn nhÃ¢n**: ChÆ°a cÃ i Ä‘áº·t ffmpeg
- **Giáº£i phÃ¡p**: CÃ i Ä‘áº·t ffmpeg theo hÆ°á»›ng dáº«n á»Ÿ trÃªn

### Realtime transcription cháº­m
- **Giáº£i phÃ¡p**: 
  - Giáº£m `MODEL_NAME` xuá»‘ng "small"
  - Sá»­ dá»¥ng GPU náº¿u cÃ³
  - TÄƒng `CHUNK_TARGET_BYTES` Ä‘á»ƒ giáº£m sá»‘ láº§n transcribe

### File upload khÃ´ng hoáº¡t Ä‘á»™ng
- **Kiá»ƒm tra**: Äáº£m báº£o file khÃ´ng quÃ¡ lá»›n (giá»›i háº¡n bá»™ nhá»›)
- **Giáº£i phÃ¡p**: Sá»­ dá»¥ng file nhá» hÆ¡n hoáº·c tÄƒng bá»™ nhá»›

### WebSocket connection failed
- **Kiá»ƒm tra**: Äáº£m báº£o server Ä‘ang cháº¡y
- **Kiá»ƒm tra**: URL WebSocket Ä‘Ãºng (ws://localhost:8917/ws)

### CUDA/cuDNN khÃ´ng tÃ¬m tháº¥y (libcudnn_ops.so.*)
- DÃ¹ng script:
  - Whisper: `backend/run_main_with_cuda.sh`
  - SenseVoice: `backend/run_main_sensevoice_with_cuda.sh`
- Hoáº·c tá»± set:
  ```bash
  export LD_LIBRARY_PATH="$CONDA_PREFIX/lib/python3.10/site-packages/nvidia/cudnn/lib:$CONDA_PREFIX/lib/python3.10/site-packages/torch/lib:$LD_LIBRARY_PATH"
  ```

## ğŸ“ Ghi chÃº

- Model Whisper/SenseVoice Ä‘Æ°á»£c táº£i tá»± Ä‘á»™ng láº§n Ä‘áº§u cháº¡y
- File táº¡m sáº½ tá»± Ä‘á»™ng xÃ³a sau khi xá»­ lÃ½ xong
- Realtime transcription sá»­ dá»¥ng buffer ~1 giÃ¢y Ä‘á»ƒ giáº£m Ä‘á»™ trá»…
- Vá»›i video files, audio sáº½ Ä‘Æ°á»£c extract tá»± Ä‘á»™ng náº¿u cÃ³ ffmpeg
- **Speaker Detection**: Sá»­ dá»¥ng SpeechBrain ECAPA-TDNN model Ä‘á»ƒ nháº­n diá»‡n ngÆ°á»i nÃ³i
  - Speaker ID Ä‘Æ°á»£c gÃ¡n dáº¡ng `spk_01`, `spk_02`, ...
  - Há»‡ thá»‘ng tá»± Ä‘á»™ng há»c vÃ  cáº­p nháº­t embedding cá»§a tá»«ng speaker
  - Khi vÆ°á»£t quÃ¡ `max_speakers`, há»‡ thá»‘ng sáº½ gÃ¡n audio má»›i cho speaker gáº§n nháº¥t
- **RTF (Real-Time Factor)**: 
  - RTF = processing_time / audio_duration
  - RTF < 1.0: Xá»­ lÃ½ nhanh hÆ¡n thá»i gian thá»±c (tá»‘t)
  - RTF = 1.0: Xá»­ lÃ½ báº±ng thá»i gian thá»±c
  - RTF > 1.0: Xá»­ lÃ½ cháº­m hÆ¡n thá»i gian thá»±c
- CÃ¡c tÃ¹y chá»n cáº¥u hÃ¬nh tá»± Ä‘á»™ng bá»‹ disable khi Ä‘ang xá»­ lÃ½ Ä‘á»ƒ trÃ¡nh thay Ä‘á»•i khÃ´ng mong muá»‘n
- Há»‡ thá»‘ng tá»± Ä‘á»™ng hiá»ƒn thá»‹/áº©n cÃ¡c pháº§n tá»­ UI dá»±a trÃªn tráº¡ng thÃ¡i (chá»‰ hiá»‡n transcript khi Ä‘ang ghi)

## ğŸ”§ Dependencies

Xem `backend/requirements.txt` Ä‘á»ƒ biáº¿t danh sÃ¡ch Ä‘áº§y Ä‘á»§.

**ChÃ­nh:**
- `fastapi`: Web framework
- `uvicorn`: ASGI server
- `numpy`: Xá»­ lÃ½ audio
- `faster-whisper`: Whisper backend
- `funasr`: SenseVoice backend

## ğŸ“„ License

Dá»± Ã¡n nÃ y sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ. Vui lÃ²ng xem license cá»§a tá»«ng thÆ° viá»‡n.

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng táº¡o issue hoáº·c pull request.

## ğŸ“§ LiÃªn há»‡

Náº¿u cÃ³ cÃ¢u há»i hoáº·c váº¥n Ä‘á», vui lÃ²ng táº¡o issue trÃªn repository.

