# result.log:
```
=== Evaluating pyannote embeddings ===
Skipped 251/15000 trials due to missing embeddings
Computing metrics on 14749 valid trials
EER: 27.77% | FAR@EER: 27.77% | FRR@EER: 27.76% | Thr(EER): 0.2995
Precision@EER: 56.56% | Recall@EER: 72.24% | F1@EER: 63.44%
Best F1: 65.28% | Precision@F1: 68.16% | Recall@F1: 62.64% | Thr(F1): 0.4175
AUC: 0.7882

=== Evaluating speechbrain embeddings ===
Skipped 251/15000 trials due to missing embeddings
Computing metrics on 14749 valid trials
EER: 15.36% | FAR@EER: 15.36% | FRR@EER: 15.37% | Thr(EER): 0.3781
Precision@EER: 73.39% | Recall@EER: 84.63% | F1@EER: 78.61%
Best F1: 86.70% | Precision@F1: 99.14% | Recall@F1: 77.03% | Thr(F1): 0.6130
AUC: 0.9369

=== Plotting curves ===

ROC curve saved to: eval_results/roc_curves.png
DET curve saved to: eval_results/det_curves.png
Precision-Recall curve saved to: eval_results/precision_recall_curves.png

=== Final Results ===
Pyannote: {'EER': 0.27769589657947646, 'threshold_at_EER': 0.299517510560555, 'FAR_at_EER': 0.2777495167361888, 'FRR_at_EER': 0.2776422764227642, 'precision_at_EER': 0.5655633354551242, 'recall_at_EER': 0.7223577235772358, 'F1_at_EER': 0.6344162799000357, 'best_F1': 0.6528277907223046, 'threshold_at_best_F1': 0.41750451029192304, 'precision_at_best_F1': 0.6815568332596197, 'recall_at_best_F1': 0.6264227642276423, 'AUC': 0.7882437237740981, 'FAR_curve': array([0.        , 0.        , 0.        , ..., 0.99989826, 0.99989826,
       1.        ], shape=(4588,)), 'FRR_curve': array([1.00000000e+00, 9.99796748e-01, 9.98780488e-01, ...,
       4.06504065e-04, 0.00000000e+00, 0.00000000e+00], shape=(4588,)), 'thresholds': array([        inf,  0.9519734 ,  0.94280498, ..., -0.1990335 ,
       -0.2250784 , -0.22687587], shape=(4588,))}
SpeechBrain: {'EER': 0.15364277933144577, 'threshold_at_EER': 0.3781467771103011, 'FAR_at_EER': 0.15362702207752568, 'FRR_at_EER': 0.15365853658536588, 'precision_at_EER': 0.7338738103630595, 'recall_at_EER': 0.8463414634146341, 'F1_at_EER': 0.7861053426467812, 'best_F1': 0.8669792977238934, 'threshold_at_best_F1': 0.6129652218046867, 'precision_at_best_F1': 0.9913680355741564, 'recall_at_best_F1': 0.7703252032520326, 'AUC': 0.9368787981805955, 'FAR_curve': array([0.        , 0.        , 0.        , ..., 0.99715129, 0.99715129,
       1.        ], shape=(1926,)), 'FRR_curve': array([1.00000000e+00, 9.99796748e-01, 2.97764228e-01, ...,
       2.03252033e-04, 0.00000000e+00, 0.00000000e+00], shape=(1926,)), 'thresholds': array([        inf,  0.9400493 ,  0.70697628, ..., -0.06335743,
       -0.06396167, -0.17806255], shape=(1926,))}
```

# 1. Nh√¨n nhanh v√†o k·∫øt qu·∫£ t·ªïng

## **Pyannote EER = 27.77% ‚Üí r·∫•t k√©m**

## **SpeechBrain EER = 15.36% ‚Üí t·ªët h∆°n r√µ r·ªát**

ƒêi·ªÅu n√†y c√≥ nghƒ©a:

* **Pyannote embeddings** ph√¢n bi·ªát speaker y·∫øu ‚Üí similarity gi·ªØa same-speaker v√† different-speaker ch·ªìng l·∫•n nhi·ªÅu.
* **SpeechBrain ECAPA embeddings** m·∫°nh h∆°n ƒë√°ng k·ªÉ ‚Üí t√°ch speaker r√µ h∆°n ‚Üí clustering t·ªët h∆°n.

---

# 2. Gi·∫£i th√≠ch t·ª´ng ph·∫ßn

## 2.1. ‚ÄúSkipped 251/15000 trials‚Äù

251 trial b·ªã b·ªè v√¨:

* 1 trong 2 file kh√¥ng c√≥ embedding (c√≥ th·ªÉ file ƒë·ªçc l·ªói / ng·∫Øn qu√° / embedding model tr·∫£ NaN / zero vector)

=> Kh√¥ng ·∫£nh h∆∞·ªüng l·ªõn (ch·ªâ ~1.6%).

---

# 3. Gi·∫£i th√≠ch metric cho t·ª´ng model

---

# üîµ PYANNOTE EMBEDDING

### **EER: 27.77%**

* Khi threshold ƒë∆∞·ª£c ch·ªânh sao cho FAR = FRR, h·ªá th·ªëng sai ~28%.
* **ƒê√¢y l√† EER r·∫•t cao**, ch·ª©ng t·ªè embedding k√©m.

Trong speaker verification:

* EER < 5%: c·ª±c t·ªët
* 5‚Äì10%: trung b√¨nh
* 10‚Äì15%: d√πng ƒë∆∞·ª£c t√πy domain
* **>20%: k√©m**
  ‚Üí Pyannote = 27.7% l√† *t·ªá r√µ r√†ng*.

---

### **FAR@EER: 27.77%**

### **FRR@EER: 27.76%**

Kh·ªõp nhau ‚Üí ƒë√∫ng ti√™u chu·∫©n EER.

---

### **Threshold_at_EER: 0.2995**

* Cosine similarity > 0.2995 ‚Üí c√πng ng∆∞·ªùi
* < 0.2995 ‚Üí kh√°c ng∆∞·ªùi

Ng∆∞·ª°ng n√†y **kh√° th·∫•p**, cho th·∫•y embedding scatter r·ªông, ph√¢n b·ªë kh√¥ng t√°ch bi·ªát.

---

### **Precision@EER: 56.56%**

Khi threshold = EER:

* Ch·ªâ 56.5% c·∫∑p predicted ‚Äúsame speaker‚Äù l√† ƒë√∫ng
  ‚Üí R·∫•t nhi·ªÅu false accept.

---

### **Recall@EER: 72.24%**

72% c·∫∑p same-speaker ƒë∆∞·ª£c nh·∫≠n ƒë√∫ng ‚Üí h∆°i kh√°, nh∆∞ng precision th·∫•p k√©o xu·ªëng ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ.

---

### **F1@EER: 63.44%**

* Trung b√¨nh y·∫øu

---

### **Best F1: 65.28% at threshold 0.4175**

N·∫øu t·ªëi ∆∞u F1:

* Precision: 68.16%
* Recall: 62.64%

F1 v·∫´n th·∫•p ‚Üí t√°ch speaker k√©m.

---

### **AUC: 0.788**

* ROC-AUC 0.78 = m·ª©c trung b√¨nh th·∫•p
* Th·ªÉ hi·ªán ph√¢n b·ªë score overlap nhi·ªÅu gi·ªØa same-speaker v√† diff-speaker.

---

# üî¥ SPEECHBRAIN EMBEDDING (ECAPA)

## **EER: 15.36%**

‚Üí T·ªët ƒë√°ng k·ªÉ so v·ªõi Pyannote (27.7%)

Kh√¥ng ph·∫£i m·ª©c SOTA (SOTA ECAPA c√≥ th·ªÉ 2‚Äì4%),
nh∆∞ng v·ªõi **micro dataset 4 style kh√°c nhau**, domain kh√°c VoxCeleb, th√¨ **15% l√† h·ª£p l√Ω v√† t·ªët**.

---

### **Precision@EER: 73.39%**

### **Recall@EER: 84.63%**

C·∫£ hai ƒë·ªÅu cao h∆°n nhi·ªÅu so v·ªõi Pyannote.

---

### **F1@EER: 78.61%**

T·ªët.

---

### **Best F1: 86.70% at threshold 0.6130**

* **Precision: 99.14%** (!)
* Recall: 77.03%

ƒêi·ªÅu n√†y n√≥i l√™n r·∫±ng:

* N·∫øu threshold ƒë·∫∑t cao (0.613) ‚Üí r·∫•t √≠t false accept (precision g·∫ßn nh∆∞ tuy·ªát ƒë·ªëi)
* Nh∆∞ng recall gi·∫£m (miss some same-speaker)

ƒê√¢y l√† ƒë·∫∑c ƒëi·ªÉm c·ªßa **embedding ph√¢n b·ªë t·ªët, tail clean**.

---

### **AUC: 0.9369**

* G·∫ßn 0.94 ‚Üí r·∫•t t·ªët
* Curves cho th·∫•y separation r√µ r√†ng.

---

# 4. Nguy√™n nh√¢n ch√≠nh khi·∫øn Pyannote embedding y·∫øu

### ‚ùå Pyannote community l√† model **segmentation-first**, embedding ch·ªâ l√† ph·ª•

* Pyannote community pipeline kh√¥ng d√πng ECAPA ho·∫∑c x-vector ƒë·ªùi m·ªõi
* Embedding c·ªßa n√≥ **thi·∫øt k·∫ø ƒë·ªÉ h·ªó tr·ª£ diarization pipeline c·ªßa ch√≠nh n√≥**, kh√¥ng ph·∫£i ƒë·ªÉ l√†m verification ƒë·ªôc l·∫≠p.

### ‚ùå ƒê∆∞·ª£c hu·∫•n luy·ªán domain kh√°c v·ªõi dataset eval

Dataset eval c√≥:

* whisper
* falsetto
* nonpara
* high pitch

  ‚Üí Nh·ªØng style n√†y **kh√°c xa** c√°c dataset m√† Pyannote community d√πng (mostly AMI/VoxConverse-style).

### ‚ùå ECAPA (SpeechBrain) l√† model **speaker verification chuy√™n d·ª•ng**

* Trained tr√™n VoxCeleb2
* Highly discriminative
* Robust v·ªõi pitch, noise, speaking style
* Do ƒë√≥ cho score t·ªët h∆°n nhi·ªÅu.

---

# 5. ƒêi·ªÅu n√†y n√≥i g√¨ cho b√†i to√°n **speaker diarization**

### ‚úî SpeechBrain ECAPA embedding s·∫Ω cho:

* Clustering t·ªët h∆°n
* √çt merge nh·∫ßm speaker
* √çt split
* Affinity matrix sharp h∆°n
* DER gi·∫£m m·∫°nh

### ‚úî Pyannote embedding s·∫Ω:

* Nhi·ªÅu false same-speaker ‚Üí merge c√°c ng∆∞·ªùi kh√°c nhau
* Nhi·ªÅu miss same-speaker ‚Üí split 1 speaker th√†nh 2‚Äì3 cluster
  ‚Üí DER r·∫•t cao.

D·ª±a tr√™n **to√†n b·ªô k·∫øt qu·∫£ EER, PR, ROC, DET v√† ph√¢n b·ªë score** m√† b·∫°n ƒë√£ t√≠nh, ta c√≥ th·ªÉ ƒë∆∞a ra **ng∆∞·ª°ng (threshold) t·ªët nh·∫•t** cho vi·ªác ph√¢n lo·∫°i **same-speaker vs different-speaker** t√πy m·ª•c ƒë√≠ch s·ª≠ d·ª•ng.

---

# ‚úÖ 1. S·ªë li·ªáu quan tr·ªçng (ƒë√£ t√≠nh tr∆∞·ªõc ƒë√≥)

### **SpeechBrain (ECAPA)**

* **Threshold t·∫°i EER:** `0.3781`
* **Threshold t·∫°i F1 t·ªët nh·∫•t:** `0.6130`
* **Precision t·∫°i F1:** ~**0.99** (g·∫ßn nh∆∞ kh√¥ng merge nh·∫ßm)
* **AUC cao:** 0.937 ‚Üí separable t·ªët

### **Pyannote**

* **Threshold t·∫°i EER:** `0.2995`
* **Threshold t·∫°i F1:** `0.4175`
  ‚Üí Embedding y·∫øu ‚Üí threshold k√©m ·ªïn ƒë·ªãnh
  => Kh√¥ng khuy·∫øn kh√≠ch d√πng ƒë·ªÉ ph√¢n lo·∫°i speaker.

V√¨ v·∫≠y **ng∆∞·ª°ng ch√≠nh c·∫ßn ch·ªçn** l√† t·ª´ **SpeechBrain ECAPA**.

---

# üéØ 2. Ch·ªçn threshold theo m·ª•c ƒë√≠ch s·ª≠ d·ª•ng

---

## üîµ Tr∆∞·ªùng h·ª£p 1: **Speaker diarization** (quan tr·ªçng nh·∫•t)

Trong diarization, **merge nh·∫ßm** (false accept) g√¢y h·∫°i n·∫∑ng h∆°n split.

‚Üí N√™n ∆∞u ti√™n **Precision cao**, ch·∫•p nh·∫≠n Recall th·∫•p h∆°n.

### **‚áí Ng∆∞·ª°ng t·ªët nh·∫•t: ~0.60 ‚Äì 0.65 (theo F1-optimal)**

#### **ƒê·ªÅ xu·∫•t: `0.61`**

V√¨ t·∫°i threshold ~0.61:

* Precision ‚âà **0.99** (h·∫ßu nh∆∞ kh√¥ng merge nh·∫ßm)
* Recall ‚âà **0.77**
* Best-F1 ƒë·∫°t **86.7%**

‚û°Ô∏è ƒê√¢y l√† **ng∆∞·ª°ng l√Ω t∆∞·ªüng ƒë·ªÉ d√πng cho clustering AHC/VBx** ‚Üí tr√°nh merge, gi·∫£m DER r·∫•t m·∫°nh.

---

## üîµ Tr∆∞·ªùng h·ª£p 2: **Speaker verification ti√™u chu·∫©n**

Mu·ªën c√¢n b·∫±ng FAR = FRR (chu·∫©n benchmark)

D√πng ng∆∞·ª°ng **EER**:

### **‚áí Ng∆∞·ª°ng: `0.378`**

T·∫°i threshold n√†y:

* FAR = FRR ‚âà 15.4%
* F1 ‚âà 78.6%
* D√πng khi b·∫°n c·∫ßn so s√°nh fairness gi·ªØa c√°c model.

---

## üîµ Tr∆∞·ªùng h·ª£p 3: **Mu·ªën Recall cao (tr√°nh split nhi·ªÅu)**

N·∫øu b·∫°n s·ª£ split nhi·ªÅu, ch·∫•p nh·∫≠n merge m·ªôt ch√∫t:

### **‚áí Ng∆∞·ª°ng: ~0.45‚Äì0.50**

* Precision 90‚Äì95%
* Recall > 85%

Nh∆∞ng **kh√¥ng n√™n d√πng cho diarization**, v√¨ merge kh√≥ s·ª≠a.

---

# üìå 3. T·ªïng h·ª£p g·ª£i √Ω ch·ªçn threshold (d·ªÖ ƒë∆∞a v√†o b√°o c√°o)

| M·ª•c ƒë√≠ch                      | Threshold similarity  | L√Ω do                              |
| ----------------------------- | --------------------- | ---------------------------------- |
| **Diarization (recommended)** | **0.60‚Äì0.65 (‚âà0.61)** | Precision ‚âà 1.0 ‚Üí kh√¥ng merge nh·∫ßm |
| Verification c√¢n b·∫±ng         | **0.378**             | FAR = FRR = EER                    |
| Mu·ªën recall cao               | **0.45‚Äì0.50**         | √çt split nh∆∞ng tƒÉng merge          |

---

# ‚≠ê 4. L·ª±a ch·ªçn cu·ªëi c√πng (g·ªçn g√†ng ‚Äì th·ª±c t·∫ø)

### **üëâ S·ª≠ d·ª•ng `0.61` l√†m threshold ph√¢n bi·ªát same/diff speaker.**

ƒê√¢y l√† ng∆∞·ª°ng:

* t·ªëi ∆∞u v·ªÅ F1
* precision c·ª±c cao
* ph√π h·ª£p nh·∫•t khi ƒë∆∞a embedding v√†o **clustering (AHC, VBx, k-means)**
* gi√∫p gi·∫£m m·∫°nh **speaker merge**, th·ª© g√¢y sai l·ªách diarization nhi·ªÅu nh·∫•t.