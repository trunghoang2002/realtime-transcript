from pyannote.audio.pipelines.speaker_diarization import SpeakerDiarization, DiarizeOutput
from pyannote.audio.pipelines.utils.hook import ProgressHook
from pyannote.audio.utils.signal import binarize
from pyannote.core import Annotation, Segment
import torch
import numpy as np
from typing import Optional, Dict, List, Callable, Union
from scipy.spatial.distance import cdist
import soundfile as sf
import tempfile
import os

class RealtimeSpeakerDiarization(SpeakerDiarization):
    """
    Realtime Speaker Diarization Pipeline with persistent speaker embeddings and session management
    
    This class extends the standard SpeakerDiarization pipeline to support:
    1. Persistent speaker tracking across multiple audio chunks
    2. Multi-session management to handle different conversations independently
    3. 2-tier speaker matching (EMA embeddings + cluster centroids)
    
    Session Management:
    -------------------
    - Each session maintains its own speaker memory and embeddings
    - Sessions are identified by unique session_id strings
    - Multiple sessions can be active simultaneously without interference
    - Use set_session(session_id) to switch between sessions
    - Use get_speaker_info(session_id) to query session state
    
    Example Usage:
    --------------
    ```python
    # Initialize pipeline
    pipeline = RealtimeSpeakerDiarization(token="your_hf_token")
    
    # Process conversation 1
    pipeline.set_session("meeting_1")
    output1 = pipeline("audio1.wav", use_memory=True, session_id="meeting_1")
    
    # Process conversation 2 (independent speakers)
    pipeline.set_session("meeting_2")
    output2 = pipeline("audio2.wav", use_memory=True, session_id="meeting_2")
    
    # Continue conversation 1
    pipeline.set_session("meeting_1")
    output3 = pipeline("audio3.wav", use_memory=True, session_id="meeting_1")
    
    # Check all sessions
    print(pipeline.list_sessions())
    print(pipeline.get_all_sessions_info())
    ```
    """
    
    def __init__(self, model_name="pyannote/speaker-diarization-community-1", 
                 token=None, cache_dir=None, 
                 similarity_threshold=0.7,  # threshold Ä‘á»ƒ match speaker
                 embedding_update_weight=0.3,  # trá»ng sá»‘ cáº­p nháº­t embedding má»›i
                 min_similarity_gap=0.3,  # gap tá»‘i thiá»ƒu Ä‘á»ƒ match (náº¿u ná»•i báº­t)
                 *args, **kwargs):
        super().__init__(
            segmentation={"checkpoint": model_name, "subfolder": "segmentation"},
            embedding={"checkpoint": model_name, "subfolder": "embedding"},
            plda={"checkpoint": model_name, "subfolder": "plda"},
            token=token, cache_dir=cache_dir, *args, **kwargs)

        # Session management
        self.current_session_id: Optional[str] = None
        self.sessions: Dict[str, Dict] = {}  # {session_id: session_data}
        
        # Config parameters
        self.similarity_threshold = similarity_threshold
        self.embedding_update_weight = embedding_update_weight
        self.min_similarity_gap = min_similarity_gap  # Gap threshold cho distinctive matching
        self.max_cluster_size = 20  # Giá»›i háº¡n sá»‘ embeddings trong cluster
    
    def _get_session_data(self, session_id: Optional[str] = None) -> Dict:
        """
        Láº¥y session data. Náº¿u khÃ´ng cÃ³ session_id, dÃ¹ng current_session_id.
        Tá»± Ä‘á»™ng táº¡o session má»›i náº¿u chÆ°a tá»“n táº¡i.
        """
        if session_id is None:
            session_id = self.current_session_id
        
        if session_id is None:
            raise ValueError("No session_id provided and no current session set. Call set_session() first.")
        
        if session_id not in self.sessions:
            # Táº¡o session má»›i
            self.sessions[session_id] = {
                'speaker_memory': {},  # {speaker_id: EMA embedding}
                'speaker_embedding_clusters': {},  # {speaker_id: [embeddings]}
                'speaker_counts': {},  # sá»‘ láº§n xuáº¥t hiá»‡n cá»§a má»—i speaker
                'speaker_history': [],  # lá»‹ch sá»­ diarization
                'total_chunks_processed': 0,
                'next_speaker_id': 0,
                'created_at': None,
                'last_updated': None
            }
            print(f"ğŸ“ Created new session: {session_id}")
        
        return self.sessions[session_id]
    
    def set_session(self, session_id: str):
        """
        Chuyá»ƒn sang session cá»¥ thá»ƒ. Tá»± Ä‘á»™ng táº¡o session má»›i náº¿u chÆ°a tá»“n táº¡i.
        
        Parameters
        ----------
        session_id : str
            ID cá»§a session cáº§n chuyá»ƒn sang
        """
        self.current_session_id = session_id
        self._get_session_data(session_id)  # Äáº£m báº£o session tá»“n táº¡i
        print(f"âœ… Switched to session: {session_id}")
    
    def get_current_session_id(self) -> Optional[str]:
        """Láº¥y ID cá»§a session hiá»‡n táº¡i"""
        return self.current_session_id
    
    def list_sessions(self) -> List[str]:
        """Liá»‡t kÃª táº¥t cáº£ session IDs"""
        return list(self.sessions.keys())
    
    def delete_session(self, session_id: str):
        """
        XÃ³a má»™t session cá»¥ thá»ƒ
        
        Parameters
        ----------
        session_id : str
            ID cá»§a session cáº§n xÃ³a
        """
        if session_id in self.sessions:
            del self.sessions[session_id]
            print(f"ğŸ—‘ï¸  Deleted session: {session_id}")
            
            # Náº¿u Ä‘ang á»Ÿ session bá»‹ xÃ³a, reset current_session_id
            if self.current_session_id == session_id:
                self.current_session_id = None
                print("âš ï¸  Current session was deleted. Please set a new session.")
        else:
            print(f"âš ï¸  Session not found: {session_id}")
    
    def reset_session(self, session_id: Optional[str] = None):
        """
        Reset má»™t session cá»¥ thá»ƒ (xÃ³a toÃ n bá»™ speaker memory nhÆ°ng giá»¯ session)
        
        Parameters
        ----------
        session_id : str, optional
            ID cá»§a session cáº§n reset. Náº¿u None, reset session hiá»‡n táº¡i.
        """
        if session_id is None:
            session_id = self.current_session_id
        
        if session_id is None:
            raise ValueError("No session_id provided and no current session set.")
        
        if session_id in self.sessions:
            self.sessions[session_id] = {
                'speaker_memory': {},
                'speaker_embedding_clusters': {},
                'speaker_counts': {},
                'speaker_history': [],
                'total_chunks_processed': 0,
                'next_speaker_id': 0,
                'created_at': self.sessions[session_id].get('created_at'),
                'last_updated': None
            }
            print(f"ğŸ”„ Reset session: {session_id}")
        else:
            print(f"âš ï¸  Session not found: {session_id}")
        
    def _match_speakers_with_memory(self, new_embeddings: np.ndarray, 
                                    new_labels: List[str],
                                    max_speakers: Optional[int] = None,
                                    session_id: Optional[str] = None) -> Dict[str, str]:
        """
        Match speakers má»›i vá»›i speakers Ä‘Ã£ biáº¿t trong memory
        Sá»­ dá»¥ng 2-tier matching: EMA embedding (fast) vÃ  cluster centroid (robust)
        
        Parameters
        ----------
        new_embeddings : (num_speakers, dimension) array
            Embeddings cá»§a speakers trong chunk hiá»‡n táº¡i
        new_labels : List[str]
            Labels táº¡m thá»i cá»§a speakers má»›i
        max_speakers : int, optional
            Maximum number of speakers allowed. If reached, force-assign to best match.
        session_id : str, optional
            Session ID to use. If None, uses current session.
            
        Returns
        -------
        mapping : Dict[str, str]
            Mapping tá»« label táº¡m thá»i -> speaker_id Ä‘Ã£ biáº¿t hoáº·c má»›i
        """
        session_data = self._get_session_data(session_id)
        speaker_memory = session_data['speaker_memory']
        speaker_embedding_clusters = session_data['speaker_embedding_clusters']
        speaker_counts = session_data['speaker_counts']
        
        if len(speaker_memory) == 0:
            # ChÆ°a cÃ³ speaker nÃ o trong memory
            mapping = {}
            for i, label in enumerate(new_labels):
                next_id = session_data['next_speaker_id']
                print(f"Creating new speaker: {label} with id: {next_id:02d}")
                speaker_id = f"SPEAKER_{next_id:02d}"
                session_data['next_speaker_id'] += 1
                mapping[label] = speaker_id
                
                # Initialize EMA embedding vÃ  cluster
                speaker_memory[speaker_id] = new_embeddings[i].copy()
                speaker_embedding_clusters[speaker_id] = [new_embeddings[i].copy()]
                speaker_counts[speaker_id] = 1
            return mapping
        
        # CÃ³ speakers trong memory - tÃ­nh similarity
        memory_speaker_ids = list(speaker_memory.keys())
        memory_embeddings = np.array([speaker_memory[sid] for sid in memory_speaker_ids])
        
        # TÃ­nh cosine similarity hoáº·c euclidean distance
        if self._embedding.metric == "cosine":
            # Cosine similarity (1 - cosine distance)
            distances = cdist(new_embeddings, memory_embeddings, metric='cosine')
            similarities_ema = 1 - distances
        else:
            # Euclidean distance -> similarity
            distances = cdist(new_embeddings, memory_embeddings, metric='euclidean')
            similarities_ema = 1 / (1 + distances)
        
        mapping = {}
        used_memory_speakers = set()
        
        # Greedy matching vá»›i 2-tier approach
        for i, label in enumerate(new_labels):
            new_embedding = new_embeddings[i]
            
            # Tier 1: So sÃ¡nh vá»›i EMA embeddings (fast path)
            best_match_idx = np.argmax(similarities_ema[i])
            best_similarity_ema = similarities_ema[i, best_match_idx]
            best_speaker_id = memory_speaker_ids[best_match_idx]
            
            # Find second best for gap analysis
            sorted_indices = np.argsort(similarities_ema[i])[::-1]  # Descending order
            second_best_similarity_ema = similarities_ema[i, sorted_indices[1]] if len(sorted_indices) > 1 else -1
            similarity_gap_ema = best_similarity_ema - second_best_similarity_ema
            
            print(f"\n[TIER 1] Label: {label}")
            print(f"  Best EMA similarity: {best_similarity_ema:.3f} with {best_speaker_id}")
            print(f"  Second best similarity: {second_best_similarity_ema:.3f}")
            print(f"  Gap: {similarity_gap_ema:.3f}")
            print(f"  Threshold: {self.similarity_threshold}")
            
            matched_speaker_id = None
            
            # Check matching conditions
            if best_speaker_id not in used_memory_speakers:
                if best_similarity_ema >= self.similarity_threshold:
                    # Match via threshold
                    matched_speaker_id = best_speaker_id
                    print(f"  âœ… Matched via EMA (threshold)!")
                elif similarity_gap_ema > self.min_similarity_gap and second_best_similarity_ema > 0:
                    # Match via significant gap
                    matched_speaker_id = best_speaker_id
                    print(f"  âœ… Matched via EMA (significant gap > {self.min_similarity_gap})!")
                
            if matched_speaker_id is None:
                # Tier 2: So sÃ¡nh vá»›i cluster centroids (robust path)
                print(f"  âŒ EMA not matched, trying cluster centroids...")
                
                cluster_similarities = []
                cluster_speaker_ids = []
                
                for speaker_id in memory_speaker_ids:
                    if speaker_id in used_memory_speakers:
                        continue
                    
                    # TÃ­nh centroid cá»§a cluster
                    cluster = speaker_embedding_clusters[speaker_id]
                    if len(cluster) > 0:
                        cluster_array = np.array(cluster)
                        centroid = np.mean(cluster_array, axis=0)
                        
                        # Normalize centroid náº¿u dÃ¹ng cosine
                        if self._embedding.metric == "cosine":
                            centroid = centroid / np.linalg.norm(centroid)
                        
                        # TÃ­nh similarity vá»›i centroid
                        if self._embedding.metric == "cosine":
                            cluster_similarity = 1 - cdist([new_embedding], [centroid], metric='cosine')[0, 0]
                        else:
                            cluster_similarity = 1 / (1 + cdist([new_embedding], [centroid], metric='euclidean')[0, 0])
                        
                        print(f"  [TIER 2] Cluster centroid similarity with {speaker_id}: {cluster_similarity:.3f}")
                        
                        cluster_similarities.append(cluster_similarity)
                        cluster_speaker_ids.append(speaker_id)
                
                # Find best and second best for gap analysis
                if len(cluster_similarities) > 0:
                    sorted_cluster_indices = np.argsort(cluster_similarities)[::-1]
                    best_cluster_idx = sorted_cluster_indices[0]
                    best_cluster_similarity = cluster_similarities[best_cluster_idx]
                    best_cluster_speaker_id = cluster_speaker_ids[best_cluster_idx]
                    
                    second_best_cluster_similarity = (
                        cluster_similarities[sorted_cluster_indices[1]] 
                        if len(sorted_cluster_indices) > 1 
                        else -1
                    )
                    cluster_similarity_gap = best_cluster_similarity - second_best_cluster_similarity
                    
                    print(f"  [TIER 2] Best: {best_cluster_similarity:.3f}, Second: {second_best_cluster_similarity:.3f}, Gap: {cluster_similarity_gap:.3f}")
                    
                    # Check matching conditions for cluster
                    if best_cluster_similarity >= self.similarity_threshold:
                        matched_speaker_id = best_cluster_speaker_id
                        print(f"  âœ… Matched via cluster centroid (threshold) with {matched_speaker_id}!")
                    elif cluster_similarity_gap > self.min_similarity_gap and second_best_cluster_similarity > 0:
                        matched_speaker_id = best_cluster_speaker_id
                        print(f"  âœ… Matched via cluster centroid (significant gap > {self.min_similarity_gap}) with {matched_speaker_id}!")
            
            # Xá»­ lÃ½ káº¿t quáº£ matching
            if matched_speaker_id is not None:
                # Match thÃ nh cÃ´ng
                mapping[label] = matched_speaker_id
                used_memory_speakers.add(matched_speaker_id)
                
                # Cáº­p nháº­t EMA embedding
                old_embedding = speaker_memory[matched_speaker_id]
                updated_embedding = (1 - self.embedding_update_weight) * old_embedding + \
                                   self.embedding_update_weight * new_embedding
                # Normalize náº¿u dÃ¹ng cosine similarity
                if self._embedding.metric == "cosine":
                    updated_embedding = updated_embedding / np.linalg.norm(updated_embedding)
                speaker_memory[matched_speaker_id] = updated_embedding
                
                # Add vÃ o cluster (vá»›i limit size)
                cluster = speaker_embedding_clusters[matched_speaker_id]
                cluster.append(new_embedding.copy())
                # Keep only recent embeddings
                if len(cluster) > self.max_cluster_size:
                    speaker_embedding_clusters[matched_speaker_id] = cluster[-self.max_cluster_size:]
                
                speaker_counts[matched_speaker_id] += 1
                print(f"  ğŸ“Š Updated: EMA + added to cluster (size: {len(speaker_embedding_clusters[matched_speaker_id])})")
                
            else:
                # KhÃ´ng match Ä‘Æ°á»£c - check max_speakers constraint
                current_num_speakers = len(speaker_memory)
                
                if max_speakers is not None and current_num_speakers >= max_speakers:
                    # ÄÃƒ Äáº T max_speakers - Force assign vÃ o speaker cÃ³ similarity cao nháº¥t
                    print(f"  âš ï¸  Max speakers ({max_speakers}) reached! Force-assigning to best match...")
                    
                    # TÃ¬m speaker cÃ³ similarity cao nháº¥t (dÃ¹ < threshold)
                    best_overall_similarity = -1
                    best_overall_speaker_id = None
                    
                    # Check both EMA and cluster similarities
                    for speaker_idx, speaker_id in enumerate(memory_speaker_ids):
                        if speaker_id in used_memory_speakers:
                            continue
                        
                        # Get EMA similarity
                        ema_sim = similarities_ema[i, speaker_idx]
                        
                        # Get cluster centroid similarity
                        cluster = speaker_embedding_clusters[speaker_id]
                        if len(cluster) > 0:
                            cluster_array = np.array(cluster)
                            centroid = np.mean(cluster_array, axis=0)
                            if self._embedding.metric == "cosine":
                                centroid = centroid / np.linalg.norm(centroid)
                            
                            if self._embedding.metric == "cosine":
                                cluster_sim = 1 - cdist([new_embedding], [centroid], metric='cosine')[0, 0]
                            else:
                                cluster_sim = 1 / (1 + cdist([new_embedding], [centroid], metric='euclidean')[0, 0])
                        else:
                            cluster_sim = ema_sim
                        
                        # # Use max of EMA and cluster similarity
                        max_sim = max(ema_sim*1.3, cluster_sim)
                        
                        if max_sim > best_overall_similarity:
                            best_overall_similarity = max_sim
                            best_overall_speaker_id = speaker_id
                    
                    if best_overall_speaker_id is not None:
                        matched_speaker_id = best_overall_speaker_id
                        mapping[label] = matched_speaker_id
                        used_memory_speakers.add(matched_speaker_id)
                        
                        print(f"  ğŸ”€ Force-assigned to {matched_speaker_id} (similarity: {best_overall_similarity:.3f})")
                        
                        # Update nhÆ° bÃ¬nh thÆ°á»ng
                        old_embedding = speaker_memory[matched_speaker_id]
                        updated_embedding = (1 - self.embedding_update_weight) * old_embedding + \
                                           self.embedding_update_weight * new_embedding
                        if self._embedding.metric == "cosine":
                            updated_embedding = updated_embedding / np.linalg.norm(updated_embedding)
                        speaker_memory[matched_speaker_id] = updated_embedding
                        
                        cluster = speaker_embedding_clusters[matched_speaker_id]
                        cluster.append(new_embedding.copy())
                        if len(cluster) > self.max_cluster_size:
                            speaker_embedding_clusters[matched_speaker_id] = cluster[-self.max_cluster_size:]
                        
                        speaker_counts[matched_speaker_id] += 1
                        print(f"  ğŸ“Š Updated: EMA + added to cluster (size: {len(speaker_embedding_clusters[matched_speaker_id])})")
                    else:
                        # Fallback: assign to first speaker (shouldn't happen)
                        fallback_speaker_id = memory_speaker_ids[0]
                        mapping[label] = fallback_speaker_id
                        print(f"  âš ï¸  Fallback: assigned to {fallback_speaker_id}")
                else:
                    # ChÆ°a Ä‘áº¡t max_speakers - Táº¡o speaker má»›i
                    next_id = session_data['next_speaker_id']
                    speaker_id = f"SPEAKER_{next_id:02d}"
                    session_data['next_speaker_id'] += 1
                    mapping[label] = speaker_id
                    
                    # Initialize EMA vÃ  cluster
                    speaker_memory[speaker_id] = new_embedding.copy()
                    speaker_embedding_clusters[speaker_id] = [new_embedding.copy()]
                    speaker_counts[speaker_id] = 1
                    print(f"  ğŸ†• Created new speaker: {speaker_id} (current total: {len(speaker_memory)})")
                
        return mapping
    
    def apply_realtime(self, audio_file: str, 
                      hook: Optional[Callable] = None,
                      use_memory: bool = True,
                      max_speakers: Optional[int] = None,
                      session_id: Optional[str] = None,
                      **kwargs) -> DiarizeOutput:
        """
        Apply diarization vá»›i context memory cho realtime processing
        
        Parameters
        ----------
        audio_file : str
            Audio file path hiá»‡n táº¡i
        hook : Optional[Callable]
            Progress hook
        use_memory : bool
            CÃ³ sá»­ dá»¥ng speaker memory hay khÃ´ng (False = xá»­ lÃ½ nhÆ° batch bÃ¬nh thÆ°á»ng)
        max_speakers : int, optional
            Maximum number of speakers. If reached, will force-assign to best match.
        session_id : str, optional
            Session ID to use. If None, uses current session. Required if use_memory=True.
        
        Returns
        -------
        output : DiarizeOutput
            Káº¿t quáº£ diarization vá»›i speaker labels Ä‘Ã£ Ä‘Æ°á»£c map vá»›i memory
        """
        # Set session if provided
        if use_memory and session_id is not None:
            self.set_session(session_id)
        elif use_memory and self.current_session_id is None:
            raise ValueError("No session_id provided and no current session set. "
                           "Call set_session() or provide session_id parameter.")

        # Gá»i phÆ°Æ¡ng thá»©c apply gá»‘c
        output = super().apply(audio_file, hook=hook, max_speakers=max_speakers, **kwargs)
        
        if not use_memory or output.speaker_embeddings is None:
            return output
        
        # Extract embeddings vÃ  labels tá»« output
        current_embeddings = output.speaker_embeddings  # (num_speakers, dimension)
        current_labels = list(output.speaker_diarization.labels())
        
        if len(current_labels) == 0:
            return output
        
        # Get session data
        session_data = self._get_session_data()
        
        # Sort labels theo thá»© tá»± thá»i gian xuáº¥t hiá»‡n Ä‘á»ƒ Ä‘áº£m báº£o consistency
        # (SPEAKER_00 nÃªn lÃ  ngÆ°á»i xuáº¥t hiá»‡n Ä‘áº§u tiÃªn)
        if len(session_data['speaker_memory']) == 0:  # Chá»‰ sort cho chunk Ä‘áº§u tiÃªn
            label_first_appearance = {}
            for turn, _, speaker in output.speaker_diarization.itertracks(yield_label=True):
                if speaker not in label_first_appearance:
                    label_first_appearance[speaker] = turn.start
            
            # Sort labels theo thá»i gian xuáº¥t hiá»‡n
            sorted_labels = sorted(current_labels, key=lambda x: label_first_appearance.get(x, float('inf')))
            
            # Reorder embeddings theo sorted labels
            label_to_idx = {label: i for i, label in enumerate(current_labels)}
            sorted_embeddings = np.array([current_embeddings[label_to_idx[label]] for label in sorted_labels])
            
            current_labels = sorted_labels
            current_embeddings = sorted_embeddings
            
            print(f"Sorted labels by appearance time: {current_labels}")
        else:
            print(f"Current labels: {current_labels}")
        
        # Match vá»›i speakers trong memory (pass max_speakers constraint)
        label_mapping = self._match_speakers_with_memory(
            current_embeddings, 
            current_labels,
            max_speakers=max_speakers
        )
        print(f"Label mapping: {label_mapping}")
        
        # Rename labels trong annotation
        diarization = output.speaker_diarization.rename_labels(mapping=label_mapping)
        print(f"Diarization: {diarization}")
        exclusive_diarization = output.exclusive_speaker_diarization.rename_labels(mapping=label_mapping)
        
        # Cáº­p nháº­t embeddings theo thá»© tá»± labels má»›i
        new_labels_ordered = list(diarization.labels())
        print(f"New labels ordered: {new_labels_ordered}")
        updated_embeddings = np.array([session_data['speaker_memory'][label] for label in new_labels_ordered])
        
        # Táº¡o output má»›i
        new_output = DiarizeOutput(
            speaker_diarization=diarization,
            exclusive_speaker_diarization=exclusive_diarization,
            speaker_embeddings=updated_embeddings
        )
        
        # LÆ°u vÃ o history
        session_data['speaker_history'].append({
            'chunk_id': session_data['total_chunks_processed'],
            'labels': new_labels_ordered,
            'num_speakers': len(new_labels_ordered)
        })
        session_data['total_chunks_processed'] += 1
        
        return new_output
    
    def get_speaker_info(self, session_id: Optional[str] = None) -> Dict:
        """
        Láº¥y thÃ´ng tin vá» cÃ¡c speakers Ä‘Ã£ biáº¿t trong session
        
        Parameters
        ----------
        session_id : str, optional
            Session ID to get info for. If None, uses current session.
            
        Returns
        -------
        info : Dict
            Dictionary containing speaker information for the session
        """
        if session_id is None and self.current_session_id is None:
            return {
                'session_id': None,
                'speakers': [],
                'speaker_counts': {},
                'cluster_sizes': {},
                'total_chunks': 0,
                'num_speakers': 0
            }
        
        session_data = self._get_session_data(session_id)
        cluster_sizes = {
            sid: len(session_data['speaker_embedding_clusters'].get(sid, []))
            for sid in session_data['speaker_memory'].keys()
        }
        return {
            'session_id': session_id or self.current_session_id,
            'speakers': list(session_data['speaker_memory'].keys()),
            'speaker_counts': session_data['speaker_counts'].copy(),
            'cluster_sizes': cluster_sizes,
            'total_chunks': session_data['total_chunks_processed'],
            'num_speakers': len(session_data['speaker_memory'])
        }
    
    def get_all_sessions_info(self) -> Dict[str, Dict]:
        """
        Láº¥y thÃ´ng tin vá» táº¥t cáº£ cÃ¡c sessions
        
        Returns
        -------
        info : Dict[str, Dict]
            Dictionary mapping session_id to session info
        """
        return {
            session_id: self.get_speaker_info(session_id)
            for session_id in self.sessions.keys()
        }
    
    def apply(self, file_or_audio_f32: Union[str, np.ndarray], hook=None, num_speakers=None, min_speakers=None, max_speakers=None, 
              use_memory=True, session_id=None, **kwargs):
        """Override apply Ä‘á»ƒ sá»­ dá»¥ng realtime mode máº·c Ä‘á»‹nh"""
        # Determine effective max_speakers
        effective_max_speakers = num_speakers if num_speakers is not None else max_speakers
        
        return self.apply_realtime(
            file_or_audio_f32, 
            hook=hook, 
            use_memory=use_memory, 
            num_speakers=num_speakers, 
            min_speakers=min_speakers, 
            max_speakers=effective_max_speakers,  # Pass effective limit
            session_id=session_id,
            **kwargs
        )

# ============ EXAMPLE USAGE ============
if __name__ == "__main__":
    # Khá»Ÿi táº¡o realtime pipeline
    import time
    start_time = time.time()
    from dotenv import load_dotenv
    load_dotenv()
    pipeline = RealtimeSpeakerDiarization(
        model_name="pyannote/speaker-diarization-community-1", 
        token=os.getenv("HF_TOKEN"),
        similarity_threshold=0.7,  # threshold Ä‘á»ƒ match speaker (cÃ ng cao cÃ ng strict)
        embedding_update_weight=0.3,  # trá»ng sá»‘ update embedding (0.3 = 30% má»›i, 70% cÅ©)
        min_similarity_gap=0.3  # gap tá»‘i thiá»ƒu Ä‘á»ƒ match náº¿u ná»•i báº­t hÆ¡n háº³n
    )

    # Send pipeline to GPU (when available)
    if torch.cuda.is_available():
        pipeline.to(torch.device("cuda"))
    end_time = time.time()
    print(f"Time taken to initialize pipeline: {end_time - start_time:.2f} seconds")
    
    # VÃ­ dá»¥ 1: Xá»­ lÃ½ má»™t audio chunk vá»›i session_id (realtime mode)
    print("=" * 100)
    print("VÃ Dá»¤ 1: Xá»­ lÃ½ audio chunk Ä‘áº§u tiÃªn vá»›i Session ID")
    print("=" * 100)
    
    # Set session for this conversation
    session_1 = "conversation_1"
    pipeline.set_session(session_1)

    with ProgressHook() as hook:
        output1 = pipeline(
            "/home/hoang/speaker_diarization/wav/TestE_sub.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=True,  # Sá»­ dá»¥ng memory Ä‘á»ƒ track speakers
            session_id=session_1  # Chá»‰ Ä‘á»‹nh session
        )

    print("\nğŸ“Š Káº¿t quáº£ chunk 1:") # 1 thá»i Ä‘iá»ƒm cÃ³ thá»ƒ cÃ³ nhiá»u speaker nÃ³i
    for turn, _, speaker in output1.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print("\nğŸ“Š Káº¿t quáº£ chunk 1 exclusive:") # 1 thá»i Ä‘iá»ƒm chá»‰ cÃ³ 1 speaker nÃ³i
    for turn, _, speaker in output1.exclusive_speaker_diarization.itertracks(yield_label=True):
        print(f"exclusive  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (Session {session_1}): {pipeline.get_speaker_info(session_1)}")
    print(f"\nğŸ“‹ All Sessions: {pipeline.list_sessions()}")

    # VÃ­ dá»¥ 2: Xá»­ lÃ½ má»™t conversation khÃ¡c vá»›i session_id khÃ¡c
    print("\n" + "=" * 100)
    print("VÃ Dá»¤ 2: Xá»­ lÃ½ conversation thá»© 2 vá»›i session khÃ¡c")
    print("=" * 100)
    
    session_2 = "conversation_2"
    pipeline.set_session(session_2)
    
    with ProgressHook() as hook:
        output2 = pipeline(
            "/home/hoang/speaker_diarization/wav/A2.wav",
            hook=hook,
            num_speakers=2,
            use_memory=True,
            session_id=session_2
        )
    
    print("\nğŸ“Š Káº¿t quáº£ chunk 1 (Session 2):")
    for turn, _, speaker in output2.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")
    
    print(f"\nğŸ’¾ Speaker Memory (Session {session_2}): {pipeline.get_speaker_info(session_2)}")
    print(f"ğŸ’¾ Speaker Memory (Session {session_1}): {pipeline.get_speaker_info(session_1)}")
    print(f"\nğŸ“‹ All Sessions: {pipeline.list_sessions()}")
    
    # VÃ­ dá»¥ 3: Quay láº¡i session 1 vÃ  xá»­ lÃ½ chunk tiáº¿p theo
    print("\n" + "=" * 100)
    print("VÃ Dá»¤ 3: Quay láº¡i Session 1 vÃ  xá»­ lÃ½ chunk tiáº¿p theo")
    print("=" * 100)
    
    pipeline.set_session(session_1)  # Chuyá»ƒn vá» session 1

    with ProgressHook() as hook:
        output3 = pipeline(
            "/home/hoang/speaker_diarization/wav/A1.wav",
            hook=hook,
            num_speakers=2,
            use_memory=True,
            session_id=session_1  # Continue with session 1
        )

    print("\nğŸ“Š Káº¿t quáº£ chunk 2 (Session 1 continued):")
    for turn, _, speaker in output3.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (Session 1 updated): {pipeline.get_speaker_info(session_1)}")
    
    # VÃ­ dá»¥ 4: Demo session management operations
    print("\n" + "=" * 100)
    print("VÃ Dá»¤ 4: Session Management - Reset vÃ  Delete")
    print("=" * 100)
    
    # Liá»‡t kÃª táº¥t cáº£ sessions
    print(f"\nğŸ“‹ Current sessions: {pipeline.list_sessions()}")
    print(f"ğŸ“ Current session ID: {pipeline.get_current_session_id()}")
    
    # Reset má»™t session (xÃ³a speaker memory nhÆ°ng giá»¯ session)
    print(f"\nğŸ”„ Resetting session: {session_1}")
    pipeline.reset_session(session_1)
    print(f"ğŸ’¾ Speaker Memory after reset: {pipeline.get_speaker_info(session_1)}")
    
    # Delete má»™t session
    # print(f"\nğŸ—‘ï¸  Deleting session: {session_2}")
    # pipeline.delete_session(session_2)
    # print(f"ğŸ“‹ Remaining sessions: {pipeline.list_sessions()}")
    
    # Xem thÃ´ng tin táº¥t cáº£ sessions
    print(f"\nğŸ“Š All sessions info:")
    for session_id, info in pipeline.get_all_sessions_info().items():
        print(f"  Session '{session_id}': {info['num_speakers']} speakers, {info['total_chunks']} chunks")
    
    print("=" * 100)

    with ProgressHook() as hook:
        output3 = pipeline(
            "/home/hoang/speaker_diarization/wav/B1.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=True
        )

    print("\nğŸ“Š Káº¿t quáº£ chunk 3:")
    for turn, _, speaker in output3.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (updated): {pipeline.get_speaker_info()}")
    print("=" * 100)
    print("=" * 100)

    with ProgressHook() as hook:
        output4 = pipeline(
            "/home/hoang/speaker_diarization/wav/A2.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=True
        )

    print("\nğŸ“Š Káº¿t quáº£ chunk 4:")
    for turn, _, speaker in output4.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (updated): {pipeline.get_speaker_info()}")
    print("=" * 100)
    print("=" * 100)

    with ProgressHook() as hook:
        output5 = pipeline(
            "/home/hoang/speaker_diarization/wav/B2.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=True
        )

    print("\nğŸ“Š Káº¿t quáº£ chunk 5:")
    for turn, _, speaker in output5.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (updated): {pipeline.get_speaker_info()}")
    print("=" * 100)
    print("=" * 100)

    with ProgressHook() as hook:
        output6 = pipeline(
            "/home/hoang/speaker_diarization/wav/A3.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=True
        )

    print("\nğŸ“Š Káº¿t quáº£ chunk 6:")
    for turn, _, speaker in output6.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (updated): {pipeline.get_speaker_info()}")
    print("=" * 100)
    print("=" * 100)

    with ProgressHook() as hook:
        output7 = pipeline(
            "/home/hoang/speaker_diarization/wav/B3.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=True
        )
    print("\nğŸ“Š Káº¿t quáº£ chunk 7:")
    for turn, _, speaker in output7.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (updated): {pipeline.get_speaker_info()}")
    print("=" * 100)
    print("=" * 100)

    with ProgressHook() as hook:
        output8 = pipeline(
            "/home/hoang/speaker_diarization/wav/TestE_sub.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=True
        )
    print("\nğŸ“Š Káº¿t quáº£ chunk 8:")
    for turn, _, speaker in output8.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")

    print(f"\nğŸ’¾ Speaker Memory (updated): {pipeline.get_speaker_info()}")
    print("=" * 100)
    print("=" * 100)

    # VÃ­ dá»¥ 3: Reset context vÃ  báº¯t Ä‘áº§u conversation má»›i
    print("\n" + "=" * 60)
    print("VÃ Dá»¤ 3: Reset context vÃ  báº¯t Ä‘áº§u láº¡i")
    print("=" * 60)

    pipeline.reset_session()
    print(f"âœ… Context Ä‘Ã£ reset: {pipeline.get_speaker_info()}")

    # VÃ­ dá»¥ 4: Disable memory (xá»­ lÃ½ nhÆ° batch mode bÃ¬nh thÆ°á»ng)
    print("\n" + "=" * 60)
    print("VÃ Dá»¤ 4: Xá»­ lÃ½ khÃ´ng dÃ¹ng memory (batch mode)")
    print("=" * 60)

    with ProgressHook() as hook:
        output3 = pipeline(
            # "/home/hoang/realtime-transcript/backend/eval/TestJ.mp3",
            "/home/hoang/speaker_diarization/wav/A1.wav",
            hook=hook,
            # min_speakers=1,
            # max_speakers=3,
            num_speakers=2,
            use_memory=False  # KhÃ´ng dÃ¹ng memory
        )

    print("\nğŸ“Š Káº¿t quáº£ batch mode:")
    for turn, _, speaker in output3.speaker_diarization.itertracks(yield_label=True):
        print(f"  â±ï¸  {turn.start:.1f}s â†’ {turn.end:.1f}s | ğŸ¤ {speaker}")