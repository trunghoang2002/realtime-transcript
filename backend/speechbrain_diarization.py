# Patch SpeechBrain compatibility issue vá»›i huggingface_hub
import fix_speechbrain  # Pháº£i import TRÆ¯á»šC speechbrain
from speechbrain.inference import EncoderClassifier
import torch
import numpy as np
from typing import Optional, Dict, List, Callable, Union
from scipy.spatial.distance import cdist
from get_audio import decode_audio

class RealtimeSpeakerDiarization():
    """
    Realtime Speaker Diarization Pipeline with persistent speaker embeddings and session management
    
    This class supports:
    1. Persistent speaker tracking across multiple audio chunks
    2. Multi-session management to handle different conversations independently
    3. 2-tier speaker matching (EMA embeddings + cluster centroids)
    
    Session Management:
    -------------------
    - Each session maintains its own speaker memory and embeddings
    - Sessions are identified by unique session_id strings
    - Multiple sessions can be active simultaneously without interference
    - Use set_session(session_id) to switch between sessions
    - Use get_speaker_info(session_id) to query session state
    
    Example Usage:
    --------------
    ```python
    # Initialize pipeline
    pipeline = RealtimeSpeakerDiarization()
    
    # Process conversation 1
    pipeline.set_session("meeting_1")
    output1 = pipeline("audio1.wav", use_memory=True, session_id="meeting_1")
    
    # Process conversation 2 (independent speakers)
    pipeline.set_session("meeting_2")
    output2 = pipeline("audio2.wav", use_memory=True, session_id="meeting_2")
    
    # Continue conversation 1
    pipeline.set_session("meeting_1")
    output3 = pipeline("audio3.wav", use_memory=True, session_id="meeting_1")
    
    # Check all sessions
    print(pipeline.list_sessions())
    print(pipeline.get_all_sessions_info())
    ```
    """
    
    def __init__(self, model_name="speechbrain/spkrec-ecapa-voxceleb",
                 similarity_threshold=0.7,  # threshold Ä‘á»ƒ match speaker
                 embedding_update_weight=0.3,  # trá»ng sá»‘ cáº­p nháº­t embedding má»›i
                 min_similarity_gap=0.3,  # gap tá»‘i thiá»ƒu Ä‘á»ƒ match (náº¿u ná»•i báº­t)
                 skip_update_short_audio=True,  # báº­t/táº¯t skip update cho audio ngáº¯n
                 min_duration_for_update=2.0,  # duration tá»‘i thiá»ƒu (giÃ¢y) Ä‘á»ƒ update embedding
                 init_similarity_threshold=0.4,  # threshold tháº¥p hÆ¡n cho chunk thá»© 2 sau init
                 *args, **kwargs):

        # Session management
        self.current_session_id: Optional[str] = None
        self.sessions: Dict[str, Dict] = {}  # {session_id: session_data}
        
        # Config parameters
        self.similarity_threshold = similarity_threshold
        self.embedding_update_weight = embedding_update_weight
        self.min_similarity_gap = min_similarity_gap  # Gap threshold cho distinctive matching
        self.max_cluster_size = 20  # Giá»›i háº¡n sá»‘ embeddings trong cluster
        self.embedding_metric = "cosine"
        self.skip_update_short_audio = skip_update_short_audio  # Skip update náº¿u audio quÃ¡ ngáº¯n
        self.min_duration_for_update = min_duration_for_update  # Duration tá»‘i thiá»ƒu Ä‘á»ƒ update
        self.init_similarity_threshold = init_similarity_threshold  # Threshold cho chunk thá»© 2 sau init

        self.spk_model = EncoderClassifier.from_hparams(
            source=model_name,
            run_opts={"device": "cuda" if torch.cuda.is_available() else "cpu"}
        )
    
    def _get_session_data(self, session_id: Optional[str] = None) -> Dict:
        """
        Láº¥y session data. Náº¿u khÃ´ng cÃ³ session_id, dÃ¹ng current_session_id.
        Tá»± Ä‘á»™ng táº¡o session má»›i náº¿u chÆ°a tá»“n táº¡i.
        """
        if session_id is None:
            session_id = self.current_session_id
        
        if session_id is None:
            raise ValueError("No session_id provided and no current session set. Call set_session() first.")
        
        if session_id not in self.sessions:
            # Táº¡o session má»›i
            self.sessions[session_id] = {
                'speaker_memory': {},  # {speaker_id: EMA embedding}
                'speaker_embedding_clusters': {},  # {speaker_id: [embeddings]}
                'speaker_counts': {},  # sá»‘ láº§n xuáº¥t hiá»‡n cá»§a má»—i speaker
                'speaker_history': [],  # lá»‹ch sá»­ diarization
                'total_chunks_processed': 0,
                'next_speaker_id': 0,
                'created_at': None,
                'last_updated': None
            }
            print(f"ğŸ“ Created new session: {session_id}")
        
        return self.sessions[session_id]
    
    def set_session(self, session_id: str):
        """
        Chuyá»ƒn sang session cá»¥ thá»ƒ. Tá»± Ä‘á»™ng táº¡o session má»›i náº¿u chÆ°a tá»“n táº¡i.
        
        Parameters
        ----------
        session_id : str
            ID cá»§a session cáº§n chuyá»ƒn sang
        """
        self.current_session_id = session_id
        self._get_session_data(session_id)  # Äáº£m báº£o session tá»“n táº¡i
        print(f"âœ… Switched to session: {session_id}")
    
    def get_current_session_id(self) -> Optional[str]:
        """Láº¥y ID cá»§a session hiá»‡n táº¡i"""
        return self.current_session_id
    
    def list_sessions(self) -> List[str]:
        """Liá»‡t kÃª táº¥t cáº£ session IDs"""
        return list(self.sessions.keys())
    
    def delete_session(self, session_id: str):
        """
        XÃ³a má»™t session cá»¥ thá»ƒ
        
        Parameters
        ----------
        session_id : str
            ID cá»§a session cáº§n xÃ³a
        """
        if session_id in self.sessions:
            del self.sessions[session_id]
            print(f"ğŸ—‘ï¸  Deleted session: {session_id}")
            
            # Náº¿u Ä‘ang á»Ÿ session bá»‹ xÃ³a, reset current_session_id
            if self.current_session_id == session_id:
                self.current_session_id = None
                print("âš ï¸  Current session was deleted. Please set a new session.")
        else:
            print(f"âš ï¸  Session not found: {session_id}")
    
    def reset_session(self, session_id: Optional[str] = None):
        """
        Reset má»™t session cá»¥ thá»ƒ (xÃ³a toÃ n bá»™ speaker memory nhÆ°ng giá»¯ session)
        
        Parameters
        ----------
        session_id : str, optional
            ID cá»§a session cáº§n reset. Náº¿u None, reset session hiá»‡n táº¡i.
        """
        if session_id is None:
            session_id = self.current_session_id
        
        if session_id is None:
            raise ValueError("No session_id provided and no current session set.")
        
        if session_id in self.sessions:
            self.sessions[session_id] = {
                'speaker_memory': {},
                'speaker_embedding_clusters': {},
                'speaker_counts': {},
                'speaker_history': [],
                'total_chunks_processed': 0,
                'next_speaker_id': 0,
                'created_at': self.sessions[session_id].get('created_at'),
                'last_updated': None
            }
            print(f"ğŸ”„ Reset session: {session_id}")
        else:
            print(f"âš ï¸  Session not found: {session_id}")
        
    def _match_speakers_with_memory(self, new_embeddings: np.ndarray, 
                                    new_labels: List[str],
                                    max_speakers: Optional[int] = None,
                                    session_id: Optional[str] = None,
                                    audio_duration: Optional[float] = None) -> Dict[str, str]:
        """
        Match speakers má»›i vá»›i speakers Ä‘Ã£ biáº¿t trong memory
        Sá»­ dá»¥ng 2-tier matching: EMA embedding (fast) vÃ  cluster centroid (robust)
        
        Parameters
        ----------
        new_embeddings : (num_speakers, dimension) array
            Embeddings cá»§a speakers trong chunk hiá»‡n táº¡i
        new_labels : List[str]
            Labels táº¡m thá»i cá»§a speakers má»›i
        max_speakers : int, optional
            Maximum number of speakers allowed. If reached, force-assign to best match.
        session_id : str, optional
            Session ID to use. If None, uses current session.
        audio_duration : float, optional
            Duration of the audio chunk in seconds. Used to determine if embedding should be updated.
            
        Returns
        -------
        mapping : Dict[str, str]
            Mapping tá»« label táº¡m thá»i -> speaker_id Ä‘Ã£ biáº¿t hoáº·c má»›i
        """
        session_data = self._get_session_data(session_id)
        speaker_memory = session_data['speaker_memory']
        speaker_embedding_clusters = session_data['speaker_embedding_clusters']
        speaker_counts = session_data['speaker_counts']
        
        # Kiá»ƒm tra xem cÃ³ nÃªn update embedding hay khÃ´ng dá»±a vÃ o duration
        should_update_embedding = True
        if self.skip_update_short_audio and audio_duration is not None:
            if audio_duration < self.min_duration_for_update:
                should_update_embedding = False
                print(f"â±ï¸  Audio duration ({audio_duration:.2f}s) < {self.min_duration_for_update}s. "
                      f"Skipping embedding update (matching only).")
        
        # Kiá»ƒm tra xem cÃ³ pháº£i chunk thá»© 2 sau init khÃ´ng (Ã¡p dá»¥ng threshold tháº¥p hÆ¡n)
        is_second_chunk_after_init = (session_data['total_chunks_processed'] == 1)
        effective_threshold = self.init_similarity_threshold if is_second_chunk_after_init else self.similarity_threshold
        
        if is_second_chunk_after_init:
            print(f"ğŸ¯ Second chunk after init - using lower threshold: {effective_threshold:.2f} (normal: {self.similarity_threshold:.2f})")
        
        if len(speaker_memory) == 0:
            # ChÆ°a cÃ³ speaker nÃ o trong memory
            mapping = {}
            for i, label in enumerate(new_labels):
                next_id = session_data['next_speaker_id']
                print(f"Creating new speaker: {label} with id: {next_id:02d}")
                speaker_id = f"SPEAKER_{next_id:02d}"
                session_data['next_speaker_id'] += 1
                mapping[label] = speaker_id
                
                # Initialize EMA embedding vÃ  cluster
                speaker_memory[speaker_id] = new_embeddings[i].copy()
                speaker_embedding_clusters[speaker_id] = [new_embeddings[i].copy()]
                speaker_counts[speaker_id] = 1
            return mapping
        
        # CÃ³ speakers trong memory - tÃ­nh similarity
        memory_speaker_ids = list(speaker_memory.keys())
        memory_embeddings = np.array([speaker_memory[sid] for sid in memory_speaker_ids])
        
        # TÃ­nh cosine similarity hoáº·c euclidean distance
        if self.embedding_metric == "cosine":
            # Cosine similarity (1 - cosine distance)
            distances = cdist(new_embeddings, memory_embeddings, metric='cosine')
            similarities_ema = 1 - distances
        else:
            # Euclidean distance -> similarity
            distances = cdist(new_embeddings, memory_embeddings, metric='euclidean')
            similarities_ema = 1 / (1 + distances)
        
        mapping = {}
        used_memory_speakers = set()
        
        # Greedy matching vá»›i 2-tier approach
        for i, label in enumerate(new_labels):
            new_embedding = new_embeddings[i]
            
            # Tier 1: So sÃ¡nh vá»›i EMA embeddings (fast path)
            best_match_idx = np.argmax(similarities_ema[i])
            best_similarity_ema = similarities_ema[i, best_match_idx]
            best_speaker_id = memory_speaker_ids[best_match_idx]
            
            # Find second best for gap analysis
            sorted_indices = np.argsort(similarities_ema[i])[::-1]  # Descending order
            second_best_similarity_ema = similarities_ema[i, sorted_indices[1]] if len(sorted_indices) > 1 else -1
            similarity_gap_ema = best_similarity_ema - second_best_similarity_ema
            
            print(f"\n[TIER 1] Label: {label}")
            print(f"  Best EMA similarity: {best_similarity_ema:.3f} with {best_speaker_id}")
            print(f"  Second best similarity: {second_best_similarity_ema:.3f}")
            print(f"  Gap: {similarity_gap_ema:.3f}")
            print(f"  Threshold: {effective_threshold}")
            
            matched_speaker_id = None
            
            # Check matching conditions
            if best_speaker_id not in used_memory_speakers:
                if best_similarity_ema >= effective_threshold:
                    # Match via threshold
                    matched_speaker_id = best_speaker_id
                    print(f"  âœ… Matched via EMA (threshold)!")
                elif similarity_gap_ema > self.min_similarity_gap and second_best_similarity_ema > 0:
                    # Match via significant gap
                    matched_speaker_id = best_speaker_id
                    print(f"  âœ… Matched via EMA (significant gap > {self.min_similarity_gap})!")
                
            if matched_speaker_id is None:
                # Tier 2: So sÃ¡nh vá»›i cluster centroids (robust path)
                print(f"  âŒ EMA not matched, trying cluster centroids...")
                
                cluster_similarities = []
                cluster_speaker_ids = []
                
                for speaker_id in memory_speaker_ids:
                    if speaker_id in used_memory_speakers:
                        continue
                    
                    # TÃ­nh centroid cá»§a cluster
                    cluster = speaker_embedding_clusters[speaker_id]
                    if len(cluster) > 0:
                        cluster_array = np.array(cluster)
                        centroid = np.mean(cluster_array, axis=0)
                        
                        # Normalize centroid náº¿u dÃ¹ng cosine
                        if self.embedding_metric == "cosine":
                            centroid = centroid / np.linalg.norm(centroid)
                        
                        # TÃ­nh similarity vá»›i centroid
                        if self.embedding_metric == "cosine":
                            cluster_similarity = 1 - cdist([new_embedding], [centroid], metric='cosine')[0, 0]
                        else:
                            cluster_similarity = 1 / (1 + cdist([new_embedding], [centroid], metric='euclidean')[0, 0])
                        
                        print(f"  [TIER 2] Cluster centroid similarity with {speaker_id}: {cluster_similarity:.3f}")
                        
                        cluster_similarities.append(cluster_similarity)
                        cluster_speaker_ids.append(speaker_id)
                
                # Find best and second best for gap analysis
                if len(cluster_similarities) > 0:
                    sorted_cluster_indices = np.argsort(cluster_similarities)[::-1]
                    best_cluster_idx = sorted_cluster_indices[0]
                    best_cluster_similarity = cluster_similarities[best_cluster_idx]
                    best_cluster_speaker_id = cluster_speaker_ids[best_cluster_idx]
                    
                    second_best_cluster_similarity = (
                        cluster_similarities[sorted_cluster_indices[1]] 
                        if len(sorted_cluster_indices) > 1 
                        else -1
                    )
                    cluster_similarity_gap = best_cluster_similarity - second_best_cluster_similarity
                    
                    print(f"  [TIER 2] Best: {best_cluster_similarity:.3f}, Second: {second_best_cluster_similarity:.3f}, Gap: {cluster_similarity_gap:.3f}")
                    
                    # Check matching conditions for cluster
                    if best_cluster_similarity >= effective_threshold:
                        matched_speaker_id = best_cluster_speaker_id
                        print(f"  âœ… Matched via cluster centroid (threshold) with {matched_speaker_id}!")
                    elif cluster_similarity_gap > self.min_similarity_gap and second_best_cluster_similarity > 0:
                        matched_speaker_id = best_cluster_speaker_id
                        print(f"  âœ… Matched via cluster centroid (significant gap > {self.min_similarity_gap}) with {matched_speaker_id}!")
            
            # Xá»­ lÃ½ káº¿t quáº£ matching
            if matched_speaker_id is not None:
                # Match thÃ nh cÃ´ng
                mapping[label] = matched_speaker_id
                used_memory_speakers.add(matched_speaker_id)
                
                # Cáº­p nháº­t EMA embedding (chá»‰ khi should_update_embedding = True)
                if should_update_embedding:
                    old_embedding = speaker_memory[matched_speaker_id]
                    updated_embedding = (1 - self.embedding_update_weight) * old_embedding + \
                                       self.embedding_update_weight * new_embedding
                    # Normalize náº¿u dÃ¹ng cosine similarity
                    if self.embedding_metric == "cosine":
                        updated_embedding = updated_embedding / np.linalg.norm(updated_embedding)
                    speaker_memory[matched_speaker_id] = updated_embedding
                    
                    # Add vÃ o cluster (vá»›i limit size)
                    cluster = speaker_embedding_clusters[matched_speaker_id]
                    cluster.append(new_embedding.copy())
                    # Keep only recent embeddings
                    if len(cluster) > self.max_cluster_size:
                        speaker_embedding_clusters[matched_speaker_id] = cluster[-self.max_cluster_size:]
                    
                    speaker_counts[matched_speaker_id] += 1
                    print(f"  ğŸ“Š Updated: EMA + added to cluster (size: {len(speaker_embedding_clusters[matched_speaker_id])})")
                else:
                    # Chá»‰ count mÃ  khÃ´ng update embedding
                    speaker_counts[matched_speaker_id] += 1
                    print(f"  ğŸ“Š Matched but skipped update (short audio)")
                
            else:
                # KhÃ´ng match Ä‘Æ°á»£c - check max_speakers constraint
                current_num_speakers = len(speaker_memory)
                
                if max_speakers is not None and current_num_speakers >= max_speakers:
                    # ÄÃƒ Äáº T max_speakers - Force assign vÃ o speaker cÃ³ similarity cao nháº¥t
                    print(f"  âš ï¸  Max speakers ({max_speakers}) reached! Force-assigning to best match...")
                    
                    # TÃ¬m speaker cÃ³ similarity cao nháº¥t (dÃ¹ < threshold)
                    best_overall_similarity = -1
                    best_overall_speaker_id = None
                    
                    # Check both EMA and cluster similarities
                    for speaker_idx, speaker_id in enumerate(memory_speaker_ids):
                        if speaker_id in used_memory_speakers:
                            continue
                        
                        # Get EMA similarity
                        ema_sim = similarities_ema[i, speaker_idx]
                        
                        # Get cluster centroid similarity
                        cluster = speaker_embedding_clusters[speaker_id]
                        if len(cluster) > 0:
                            cluster_array = np.array(cluster)
                            centroid = np.mean(cluster_array, axis=0)
                            if self.embedding_metric == "cosine":
                                centroid = centroid / np.linalg.norm(centroid)
                            
                            if self.embedding_metric == "cosine":
                                cluster_sim = 1 - cdist([new_embedding], [centroid], metric='cosine')[0, 0]
                            else:
                                cluster_sim = 1 / (1 + cdist([new_embedding], [centroid], metric='euclidean')[0, 0])
                        else:
                            cluster_sim = ema_sim
                        
                        # # Use max of EMA and cluster similarity
                        max_sim = max(ema_sim*1.3, cluster_sim)
                        
                        if max_sim > best_overall_similarity:
                            best_overall_similarity = max_sim
                            best_overall_speaker_id = speaker_id
                    
                    if best_overall_speaker_id is not None:
                        matched_speaker_id = best_overall_speaker_id
                        mapping[label] = matched_speaker_id
                        used_memory_speakers.add(matched_speaker_id)
                        
                        print(f"  ğŸ”€ Force-assigned to {matched_speaker_id} (similarity: {best_overall_similarity:.3f})")
                        
                        # Update nhÆ° bÃ¬nh thÆ°á»ng (chá»‰ khi should_update_embedding = True)
                        if should_update_embedding:
                            old_embedding = speaker_memory[matched_speaker_id]
                            updated_embedding = (1 - self.embedding_update_weight) * old_embedding + \
                                               self.embedding_update_weight * new_embedding
                            if self.embedding_metric == "cosine":
                                updated_embedding = updated_embedding / np.linalg.norm(updated_embedding)
                            speaker_memory[matched_speaker_id] = updated_embedding
                            
                            cluster = speaker_embedding_clusters[matched_speaker_id]
                            cluster.append(new_embedding.copy())
                            if len(cluster) > self.max_cluster_size:
                                speaker_embedding_clusters[matched_speaker_id] = cluster[-self.max_cluster_size:]
                            
                            speaker_counts[matched_speaker_id] += 1
                            print(f"  ğŸ“Š Updated: EMA + added to cluster (size: {len(speaker_embedding_clusters[matched_speaker_id])})")
                        else:
                            # Chá»‰ count mÃ  khÃ´ng update embedding
                            speaker_counts[matched_speaker_id] += 1
                            print(f"  ğŸ“Š Force-assigned but skipped update (short audio)")
                    else:
                        # Fallback: assign to first speaker (shouldn't happen)
                        fallback_speaker_id = memory_speaker_ids[0]
                        mapping[label] = fallback_speaker_id
                        print(f"  âš ï¸  Fallback: assigned to {fallback_speaker_id}")
                else:
                    # ChÆ°a Ä‘áº¡t max_speakers - Táº¡o speaker má»›i
                    next_id = session_data['next_speaker_id']
                    speaker_id = f"SPEAKER_{next_id:02d}"
                    session_data['next_speaker_id'] += 1
                    mapping[label] = speaker_id
                    
                    # Initialize EMA vÃ  cluster
                    speaker_memory[speaker_id] = new_embedding.copy()
                    speaker_embedding_clusters[speaker_id] = [new_embedding.copy()]
                    speaker_counts[speaker_id] = 1
                    print(f"  ğŸ†• Created new speaker: {speaker_id} (current total: {len(speaker_memory)})")
                
        return mapping
    
    def apply_realtime(self, file_or_audio_f32: Union[str, np.ndarray], 
                      use_memory: bool = True,
                      max_speakers: Optional[int] = None,
                      session_id: Optional[str] = None,
                      **kwargs) -> dict:
        """
        Apply diarization vá»›i context memory cho realtime processing
        
        Parameters
        ----------
        file_or_audio_f32 : Union[str, np.ndarray]
            Audio chunk hiá»‡n táº¡i hoáº·c file path
        use_memory : bool
            CÃ³ sá»­ dá»¥ng speaker memory hay khÃ´ng (False = xá»­ lÃ½ nhÆ° batch bÃ¬nh thÆ°á»ng)
        max_speakers : int, optional
            Maximum number of speakers. If reached, will force-assign to best match.
        session_id : str, optional
            Session ID to use. If None, uses current session. Required if use_memory=True.
        
        Returns
        -------
        output : dict
            Káº¿t quáº£ diarization vá»›i speaker labels Ä‘Ã£ Ä‘Æ°á»£c map vá»›i memory
        """
        # Set session if provided
        if use_memory and session_id is not None:
            self.set_session(session_id)
        elif use_memory and self.current_session_id is None:
            raise ValueError("No session_id provided and no current session set. "
                           "Call set_session() or provide session_id parameter.")
        # Gá»i phÆ°Æ¡ng thá»©c apply gá»‘c
        output = {}

        if isinstance(file_or_audio_f32, str):
            audio_f32 = decode_audio(file_or_audio_f32)
        else:
            audio_f32 = file_or_audio_f32
        
        # TÃ­nh duration
        audio_duration = audio_f32.shape[0] / 16000
        print(f"duration: {audio_duration:.2f}s")

         # === TrÃ­ch embedding ===
        # SpeechBrain yÃªu cáº§u tensor shape (batch, time)
        try:
            tensor = torch.tensor(audio_f32).unsqueeze(0)
            with torch.no_grad():
                emb = self.spk_model.encode_batch(tensor).detach().cpu().numpy().mean(axis=1)[0]
        except Exception:
            return output
    
        # Normalize embedding Ä‘á»ƒ á»•n Ä‘á»‹nh hÆ¡n
        emb_norm = emb / (np.linalg.norm(emb) + 1e-8)
        emb_norm = np.expand_dims(emb_norm, axis=0)
        output['speaker_embeddings'] = emb_norm
        output['speaker_labels'] = ['SPEAKER_00']


        if not use_memory or output['speaker_embeddings'] is None:
            return output
        
        # Get session data
        session_data = self._get_session_data()
        
        # Extract embeddings vÃ  labels tá»« output
        current_embeddings = output['speaker_embeddings']  # (num_speakers, dimension)
        current_labels = output['speaker_labels']
        
        
        # Match vá»›i speakers trong memory (pass max_speakers constraint vÃ  audio_duration)
        label_mapping = self._match_speakers_with_memory(
            current_embeddings, 
            current_labels,
            max_speakers=max_speakers,
            audio_duration=audio_duration
        )
        print(f"Label mapping: {label_mapping}")
        
        # Cáº­p nháº­t embeddings theo thá»© tá»± labels má»›i
        new_labels_ordered = list(label_mapping.values())
        print(f"New labels ordered: {new_labels_ordered}")
        updated_embeddings = np.array([session_data['speaker_memory'][label] for label in new_labels_ordered])
        
        output['speaker_labels'] = new_labels_ordered
        output['speaker_embeddings'] = updated_embeddings

        # LÆ°u vÃ o history
        session_data['speaker_history'].append({
            'chunk_id': session_data['total_chunks_processed'],
            'labels': new_labels_ordered,
            'num_speakers': len(new_labels_ordered)
        })
        session_data['total_chunks_processed'] += 1
        
        return output
    
    def get_speaker_info(self, session_id: Optional[str] = None) -> Dict:
        """
        Láº¥y thÃ´ng tin vá» cÃ¡c speakers Ä‘Ã£ biáº¿t trong session
        
        Parameters
        ----------
        session_id : str, optional
            Session ID to get info for. If None, uses current session.
            
        Returns
        -------
        info : Dict
            Dictionary containing speaker information for the session
        """
        if session_id is None and self.current_session_id is None:
            return {
                'session_id': None,
                'speakers': [],
                'speaker_counts': {},
                'cluster_sizes': {},
                'total_chunks': 0,
                'num_speakers': 0
            }
        
        session_data = self._get_session_data(session_id)
        cluster_sizes = {
            sid: len(session_data['speaker_embedding_clusters'].get(sid, []))
            for sid in session_data['speaker_memory'].keys()
        }
        return {
            'session_id': session_id or self.current_session_id,
            'speakers': list(session_data['speaker_memory'].keys()),
            'speaker_counts': session_data['speaker_counts'].copy(),
            'cluster_sizes': cluster_sizes,
            'total_chunks': session_data['total_chunks_processed'],
            'num_speakers': len(session_data['speaker_memory'])
        }
    
    def get_all_sessions_info(self) -> Dict[str, Dict]:
        """
        Láº¥y thÃ´ng tin vá» táº¥t cáº£ cÃ¡c sessions
        
        Returns
        -------
        info : Dict[str, Dict]
            Dictionary mapping session_id to session info
        """
        return {
            session_id: self.get_speaker_info(session_id)
            for session_id in self.sessions.keys()
        }
    
    def __call__(self, file_or_audio_f32: Union[str, np.ndarray], num_speakers=None, min_speakers=None, max_speakers=None, 
              use_memory=True, session_id=None, **kwargs):
        """Override apply Ä‘á»ƒ sá»­ dá»¥ng realtime mode máº·c Ä‘á»‹nh"""
        # Determine effective max_speakers
        effective_max_speakers = num_speakers if num_speakers is not None else max_speakers
        
        return self.apply_realtime(
            file_or_audio_f32, 
            use_memory=use_memory, 
            num_speakers=num_speakers, 
            min_speakers=min_speakers, 
            max_speakers=effective_max_speakers,  # Pass effective limit
            session_id=session_id,
            **kwargs
        )

# ============ EXAMPLE USAGE ============
if __name__ == "__main__":
    # Khá»Ÿi táº¡o realtime pipeline
    pipeline = RealtimeSpeakerDiarization(
        similarity_threshold=0.7,  # threshold Ä‘á»ƒ match speaker (cÃ ng cao cÃ ng strict)
        embedding_update_weight=0.3,  # trá»ng sá»‘ update embedding (0.3 = 30% má»›i, 70% cÅ©)
        min_similarity_gap=0.3,  # gap tá»‘i thiá»ƒu Ä‘á»ƒ match náº¿u ná»•i báº­t hÆ¡n háº³n
        skip_update_short_audio=True,  # báº­t tÃ­nh nÄƒng skip update cho audio ngáº¯n
        min_duration_for_update=2.0,  # chá»‰ update embedding náº¿u audio >= 2s
        init_similarity_threshold=0.4  # threshold tháº¥p hÆ¡n cho chunk thá»© 2 sau init
    )

    # VÃ­ dá»¥ 1: Xá»­ lÃ½ audio chunk Ä‘áº§u tiÃªn vá»›i Session ID
    print("=" * 100)
    print("VÃ Dá»¤ 1: Xá»­ lÃ½ audio chunk Ä‘áº§u tiÃªn vá»›i Session ID")
    print("=" * 100)
    
    # Set session for this conversation
    session_1 = "conversation_1"
    pipeline.set_session(session_1)

    output1 = pipeline(
        "/home/hoang/speaker_diarization/wav/A1.wav",
        num_speakers=2,
        use_memory=True,
        session_id=session_1
    )

    print("\nğŸ“Š Káº¿t quáº£ chunk 1:")
    print(f"  ğŸ¤ {output1['speaker_labels']}")

    print(f"\nğŸ’¾ Speaker Memory (Session {session_1}): {pipeline.get_speaker_info(session_1)}")
    print(f"\nğŸ“‹ All Sessions: {pipeline.list_sessions()}")

    # VÃ­ dá»¥ 2: Xá»­ lÃ½ má»™t conversation khÃ¡c vá»›i session_id khÃ¡c
    print("\n" + "=" * 100)
    print("VÃ Dá»¤ 2: Xá»­ lÃ½ conversation thá»© 2 vá»›i session khÃ¡c")
    print("=" * 100)
    
    session_2 = "conversation_2"
    pipeline.set_session(session_2)

    output2 = pipeline(
        "/home/hoang/speaker_diarization/wav/A2.wav",
        num_speakers=2,
        use_memory=True,
        session_id=session_2
    )

    print("\nğŸ“Š Káº¿t quáº£ chunk 1 (Session 2):")
    print(f"  ğŸ¤ {output2['speaker_labels']}")

    print(f"\nğŸ’¾ Speaker Memory (Session {session_2}): {pipeline.get_speaker_info(session_2)}")
    print(f"ğŸ’¾ Speaker Memory (Session {session_1}): {pipeline.get_speaker_info(session_1)}")
    print(f"\nğŸ“‹ All Sessions: {pipeline.list_sessions()}")

    # VÃ­ dá»¥ 3: Quay láº¡i session 1 vÃ  xá»­ lÃ½ chunk tiáº¿p theo
    print("\n" + "=" * 100)
    print("VÃ Dá»¤ 3: Quay láº¡i Session 1 vÃ  xá»­ lÃ½ chunk tiáº¿p theo")
    print("=" * 100)
    
    pipeline.set_session(session_1)  # Chuyá»ƒn vá» session 1

    output3 = pipeline(
        "/home/hoang/speaker_diarization/wav/B1.wav",
        num_speakers=2,
        use_memory=True,
        session_id=session_1
    )

    print("\nğŸ“Š Káº¿t quáº£ chunk 2 (Session 1 continued):")
    print(f"  ğŸ¤ {output3['speaker_labels']}")

    print(f"\nğŸ’¾ Speaker Memory (Session 1 updated): {pipeline.get_speaker_info(session_1)}")
    
    # VÃ­ dá»¥ 4: Demo session management operations
    print("\n" + "=" * 100)
    print("VÃ Dá»¤ 4: Session Management - Reset vÃ  Delete")
    print("=" * 100)
    
    # Liá»‡t kÃª táº¥t cáº£ sessions
    print(f"\nğŸ“‹ Current sessions: {pipeline.list_sessions()}")
    print(f"ğŸ“ Current session ID: {pipeline.get_current_session_id()}")
    
    # Reset má»™t session (xÃ³a speaker memory nhÆ°ng giá»¯ session)
    print(f"\nğŸ”„ Resetting session: {session_1}")
    pipeline.reset_session(session_1)
    print(f"ğŸ’¾ Speaker Memory after reset: {pipeline.get_speaker_info(session_1)}")
    
    # Xem thÃ´ng tin táº¥t cáº£ sessions
    print(f"\nğŸ“Š All sessions info:")
    for session_id, info in pipeline.get_all_sessions_info().items():
        print(f"  Session '{session_id}': {info['num_speakers']} speakers, {info['total_chunks']} chunks")

    print(f"\nğŸ’¾ Speaker Memory (updated): {pipeline.get_speaker_info()}")
    print("=" * 100)