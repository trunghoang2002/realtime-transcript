## üß© 1. T·ªïng quan v·ªÅ `WhisperModel`

`WhisperModel` l√† l·ªõp ch√≠nh d√πng ƒë·ªÉ:

* **T·∫£i model Whisper** (c√°c bi·∫øn th·ªÉ: tiny, base, small, medium, large, large-v2/v3).
* **Ch·∫°y inference** v·ªõi input l√† m·∫£ng √¢m thanh (`numpy`).
* **Tr·∫£ v·ªÅ k·∫øt qu·∫£ d·∫°ng segment (ƒëo·∫°n c√≥ th·ªùi gian + text)**.

```python
from faster_whisper import WhisperModel

model = WhisperModel(
    model_size_or_path="medium",
    device="cuda",          # ho·∫∑c "cpu"
    compute_type="float16", # ho·∫∑c "int8" ƒë·ªÉ gi·∫£m RAM
)
```

---

## ‚öôÔ∏è 2. C√°c tham s·ªë ch√≠nh khi kh·ªüi t·∫°o

| Tham s·ªë                | M√¥ t·∫£ chi ti·∫øt                                                                                                              |
| ---------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| **model_size_or_path** | T√™n model ho·∫∑c ƒë∆∞·ªùng d·∫´n local. <br>V√≠ d·ª•: `"tiny"`, `"small"`, `"medium"`, `"large-v3"`, ho·∫∑c `"./models/whisper-medium"`. |
| **device**             | `"cpu"`, `"cuda"`, `"auto"`. <br>N·∫øu c√≥ GPU, n√™n d√πng `"cuda"`.                                                             |
| **compute_type**       | Ki·ªÉu t√≠nh to√°n: <br>- `"float16"` ‚Üí nhanh, GPU<br>- `"int8"` / `"int8_float16"` ‚Üí ti·∫øt ki·ªám RAM, d√πng CPU.                  |
| **cpu_threads**        | S·ªë lu·ªìng CPU (m·∫∑c ƒë·ªãnh = all). Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh qu√° t·∫£i CPU.                                                               |
| **num_workers**        | S·ªë ti·∫øn tr√¨nh x·ª≠ l√Ω batch audio song song. H·ªØu √≠ch n·∫øu d√πng nhi·ªÅu GPU ho·∫∑c nhi·ªÅu file.                                      |
| **download_root**      | Th∆∞ m·ª•c ch·ª©a model t·∫£i v·ªÅ. M·∫∑c ƒë·ªãnh `~/.cache/whisper`.                                                                     |

---

## üîç 3. Ph∆∞∆°ng th·ª©c `transcribe()`

C·∫•u tr√∫c c∆° b·∫£n:

```python
segments, info = model.transcribe(
    audio,                     # numpy array float32 (mono 16kHz)
    beam_size=5,               # decoding beam width
    language="vi",             # "auto" ho·∫∑c m√£ ISO (en, ja, vi, ...)
    temperature=0.0,           # 0.0‚Äì1.0, th·∫•p -> √≠t l·ªói ng·∫´u nhi√™n
    best_of=5,                 # l·∫•y best-of-N candidate
    vad_filter=True,           # b·∫≠t l·ªçc im l·∫∑ng (Voice Activity Detection)
    vad_parameters=dict(min_silence_duration_ms=200),
    condition_on_previous_text=True,  # gi·ªØ ng·ªØ c·∫£nh gi·ªØa c√°c chunk
    initial_prompt=None,       # prompt g·ª£i √Ω n·ªôi dung ban ƒë·∫ßu
    word_timestamps=False,     # tr·∫£ timestamp cho t·ª´ng t·ª´
    no_speech_threshold=0.6,   # ng∆∞·ª°ng im l·∫∑ng
    compression_ratio_threshold=2.4,
    log_prob_threshold=-1.0,
    patience=1.0,              # beam search early stopping
    suppress_tokens=[-1],      # token b·ªã lo·∫°i b·ªè
)
```

### üìò Gi·∫£i th√≠ch c√°c tham s·ªë quan tr·ªçng

| Nh√≥m                             | Tham s·ªë                                                                    | Gi·∫£i th√≠ch                                                                                                                  |
| -------------------------------- | -------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| **Ng√¥n ng·ªØ & kh·ªüi t·∫°o**          | `language`, `initial_prompt`                                               | C√≥ th·ªÉ √©p model d√πng ti·∫øng c·ª• th·ªÉ, gi√∫p nhanh v√† ·ªïn ƒë·ªãnh h∆°n so v·ªõi auto detect.                                            |
| **Ch√≠nh x√°c vs t·ªëc ƒë·ªô**          | `beam_size`, `best_of`, `temperature`                                      | - TƒÉng `beam_size` ‚Üí ch√≠nh x√°c h∆°n, nh∆∞ng ch·∫≠m.<br>- `best_of=1`, `beam_size=1` ‚Üí realtime h∆°n.                             |
| **Streaming / segment r·ªùi nhau** | `condition_on_previous_text`                                               | N·∫øu `False`, m·ªói chunk ƒë∆∞·ª£c d·ªãch ƒë·ªôc l·∫≠p (th√≠ch h·ª£p realtime). N·∫øu `True`, gi·ªØ ng·ªØ c·∫£nh gi·ªØa c√°c ƒëo·∫°n (th√≠ch h·ª£p file d√†i). |
| **X·ª≠ l√Ω im l·∫∑ng**                | `vad_filter`, `vad_parameters`                                             | Lo·∫°i b·ªè ph·∫ßn im l·∫∑ng tr∆∞·ªõc khi decode, gi√∫p gi·∫£m latency.                                                                   |
| **C·∫Øt ng·∫Øn l·ªói**                 | `no_speech_threshold`, `compression_ratio_threshold`, `log_prob_threshold` | D√πng ƒë·ªÉ lo·∫°i b·ªè segment b·ªã sai (noise).                                                                                     |
| **Th√¥ng tin ƒë·∫ßu ra**             | `word_timestamps=True`                                                     | Tr·∫£ th√™m timestamp t·ª´ng t·ª´ (ph√π h·ª£p l√†m karaoke ho·∫∑c highlight UI).                                                         |

---

## üß† 4. Output tr·∫£ v·ªÅ

### D·∫°ng 1 ‚Äî Generator segments

```python
for segment in segments:
    print(f"[{segment.start:.2f}s ‚Üí {segment.end:.2f}s] {segment.text}")
```

M·ªói `segment` c√≥:

* `.start`, `.end` ‚Äî th·ªùi gian (gi√¢y)
* `.text` ‚Äî chu·ªói ƒë√£ nh·∫≠n d·∫°ng
* `.words` ‚Äî n·∫øu b·∫≠t `word_timestamps`

### D·∫°ng 2 ‚Äî Th√¥ng tin chung

`info` ch·ª©a:

* `language`: m√£ ng√¥n ng·ªØ ph√°t hi·ªán
* `language_probability`: x√°c su·∫•t
* `duration`: ƒë·ªô d√†i audio
* `transcription_time`: th·ªùi gian x·ª≠ l√Ω

---

## ‚ö° 5. C√°c ch·∫ø ƒë·ªô t·ªëi ∆∞u hi·ªáu nƒÉng

| Tr∆∞·ªùng h·ª£p                   | C·∫•u h√¨nh g·ª£i √Ω                                                                       |
| ---------------------------- | ------------------------------------------------------------------------------------ |
| **Realtime, latency th·∫•p**   | `beam_size=1`, `best_of=1`, `temperature=0.0`, `condition_on_previous_text=False`    |
| **Ch√≠nh x√°c cao (file d√†i)** | `beam_size=5`, `best_of=5`, `temperature=0.2‚Äì0.5`, `condition_on_previous_text=True` |
| **Server CPU y·∫øu**           | `compute_type="int8"`, `vad_filter=True`, `model="small"`                            |
| **GPU inference**            | `device="cuda"`, `compute_type="float16"`, `model="medium"` ho·∫∑c `large-v3`          |

---

## üß© 6. So s√°nh nhanh c√°c model

| Model    | K√≠ch th∆∞·ªõc | Ng√¥n ng·ªØ | RAM c·∫ßn (FP16) | T·ªëc ƒë·ªô (real-time) | ƒê·ªô ch√≠nh x√°c |
| -------- | ---------- | -------- | -------------- | ------------------ | ------------ |
| tiny     | 39 MB      | ~50      | <1 GB          | 8√ó nhanh           | th·∫•p         |
| base     | 74 MB      | ~50      | 1 GB           | 5√ó nhanh           | trung b√¨nh   |
| small    | 244 MB     | ~50      | 2 GB           | 2√ó nhanh           | t·ªët          |
| medium   | 769 MB     | ~50      | 5 GB           | 1√ó                 | cao          |
| large-v3 | 1.5 GB     | ~100     | 10 GB          | 0.5√ó               | r·∫•t cao      |

---

## üß™ 7. V√≠ d·ª• ƒë·∫ßy ƒë·ªß

```python
from faster_whisper import WhisperModel
import numpy as np
import soundfile as sf

model = WhisperModel("small", device="cuda", compute_type="float16")

audio, sr = sf.read("sample.wav")
assert sr == 16000

segments, info = model.transcribe(
    audio,
    language="vi",
    beam_size=1,
    vad_filter=True,
    condition_on_previous_text=False
)

for seg in segments:
    print(f"[{seg.start:.2f}s - {seg.end:.2f}s] {seg.text}")
```

---

## ‚úÖ 8. Khi d√πng cho realtime transcript

| M·ª•c ti√™u                          | Khuy·∫øn ngh·ªã                                                        |
| --------------------------------- | ------------------------------------------------------------------ |
| T·ªëc ƒë·ªô ph·∫£n h·ªìi nhanh             | `beam_size=1`, `best_of=1`, `vad_filter=True`                      |
| Gi·∫£m drift vƒÉn b·∫£n gi·ªØa c√°c chunk | `condition_on_previous_text=False`                                 |
| Ti·∫øng Vi·ªát ·ªïn ƒë·ªãnh                | `language="vi"`                                                    |
| Nhi·ªÖu mic                         | B·∫≠t `vad_filter`, `min_silence_duration_ms=150`                    |
| √Çm thanh d√†i (offline)            | Chia th√†nh c√°c block 30‚Äì60s, gi·ªØ `condition_on_previous_text=True` |

---
